{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp4l-UQPG_WS"
      },
      "source": [
        "## Document Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "Sh2L4oUbG_WW",
        "outputId": "376188c4-d10c-4aa0-ab94-44593f288261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.0.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.0.1%2Bcpu-cp310-cp310-linux_x86_64.whl (195.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.15.2%2Bcpu-cp310-cp310-linux_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.15.2+cpu\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.15.2%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cpu) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cpu) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cpu) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cpu) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cpu) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cpu) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cpu) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cpu) (11.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2+cpu) (4.67.1)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2+cpu)\n",
            "  Downloading https://download.pytorch.org/whl/torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2+cpu) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1+cpu) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cpu) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cpu) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cpu) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1+cpu) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.10.1\n",
            "    Uninstalling torchdata-0.10.1:\n",
            "      Successfully uninstalled torchdata-0.10.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1+cpu torchdata-0.6.1 torchtext-0.15.2+cpu torchvision-0.15.2+cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "aef916c222794376a2c9fea0d3c333b9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -qq torchtext\n",
        "!pip install -qq torchdata\n",
        "!pip install torch==2.0.1+cpu torchvision==0.15.2+cpu torchtext==0.15.2+cpu --index-url https://download.pytorch.org/whl/cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNfy4B8cK87P",
        "outputId": "515e6e9e-70c1-4e90-8ffb-d3c2252e1499"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import accumulate\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torchtext.datasets import AG_NEWS\n",
        "from IPython.display import Markdown as md\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import AG_NEWS\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-aIybIzAHA5b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(COST,ACC):\n",
        "    fig, ax1 = plt.subplots()\n",
        "    color = 'tab:red'\n",
        "    ax1.plot(COST, color=color)\n",
        "    ax1.set_xlabel('epoch', color=color)\n",
        "    ax1.set_ylabel('total loss', color=color)\n",
        "    ax1.tick_params(axis='y', color=color)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('accuracy', color=color)  # you already handled the x-label with ax1\n",
        "    ax2.plot(ACC, color=color)\n",
        "    ax2.tick_params(axis='y', color=color)\n",
        "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wPS5rC5fKpS8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating iterator and checking text, associated labels"
      ],
      "metadata": {
        "id": "GRJk4svJMtRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter= iter(AG_NEWS(split=\"train\"))"
      ],
      "metadata": {
        "id": "j4IOjXZAKtID"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = sum(1 for _ in train_iter)  # Count the number of items\n",
        "print(f\"Size of train_iter: {size}\")"
      ],
      "metadata": {
        "id": "G6MzE5gPrdWM",
        "outputId": "6691406f-03ae-4b0d-e831-147aa39ee024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train_iter: 120000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter= iter(AG_NEWS(split=\"train\"))\n",
        "y,text= next((train_iter))\n",
        "print(y,text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW0ea2oULBk4",
        "outputId": "c7455b56-8522-4a4e-e562-6549008b7b70"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next((train_iter)) ## we can use next and keep iterating and get label, text"
      ],
      "metadata": {
        "id": "OPlaFPv2tVJg",
        "outputId": "2e1fd650-2c8c-492e-d702-5cfc0afdadb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
        "ag_news_label[y]"
      ],
      "metadata": {
        "id": "c0U4_nkpMngH",
        "outputId": "a885fdf9-3ec0-4672-f596-deff41162d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Business'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = len(set([label for (label, text) in train_iter ]))\n",
        "num_class"
      ],
      "metadata": {
        "id": "R9DGOi7SM3kw",
        "outputId": "83d360aa-a425-4f1a-ea5d-db1e7c30f7df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THfWT9yyy9FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "1iO7i7iY2z9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is an Iterable?\n",
        "\n",
        "Definition: An iterable is any Python object that can be looped over (iterated through). It contains elements that you can access one at a time.\n",
        "Key Property: An iterable implements the __iter__() method, which returns an iterator.\n",
        "\n",
        "Examples: Lists, tuples, dictionaries, strings, and objects that define __iter__() or __getitem__(). How to Identify an Iterable\n",
        "\n",
        "You can pass an iterable to iter() to get an iterator. **AG_NEWS is an iterable object**\n",
        "\n",
        "The AG_NEWS dataset in torchtext does not support direct indexing like a list or tuple. It is not a random access dataset but rather an iterable dataset that needs to be used with an iterator. This approach is more effective for text data.\n",
        "\n"
      ],
      "metadata": {
        "id": "t6-LMaz1y9ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reinitialize train_iter, loads AG_NEWS dataset which contains labels and text, without iter. AG_NEWS is an iterable object\n",
        "train_iter = AG_NEWS(split=\"train\")\n",
        "\n",
        "\n",
        "# Define tokenizer and yield_tokens\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# The purpose of the generator function yield_tokens is to yield tokenized texts one at a time.\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text.lower())  # Lowercase conversion for consistency"
      ],
      "metadata": {
        "id": "3VMo2O75NCf9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we had initalized AG News with iter and then called yield_tokens then it will give you list of tokens for one sentence at a time and then calling next(yield_tokens(train_iter)) will give next sentence list of tokens.\n",
        "\n",
        "What build_vocab_from_iterator Expects?\n",
        "\n",
        "The function build_vocab_from_iterator works with any iterable that provides tokens one at a time. It does not require an explicit iterator.\n",
        "It will internally convert the iterable into an iterator using iter() if necessary."
      ],
      "metadata": {
        "id": "kJnVvu5tuXW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build vocabulary, unk for unknown words\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# Print the vocabulary size and sample tokens\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "print(f\"Sample tokens: {list(vocab.get_stoi().keys())[:10]}\")\n"
      ],
      "metadata": {
        "id": "FmAwGfQXrCG6",
        "outputId": "65e0e6dd-6424-4ad8-f314-27492d21f325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 95811\n",
            "Sample tokens: ['zzz', 'zygmunt', 'zwiki', 'zvidauri', 'zurine', 'zurab', 'zuo', 'zuloaga', 'zovko', 'zotinca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab([\"age\",\"hello\"]) ## get token indices"
      ],
      "metadata": {
        "id": "AEE44_H7vNHU",
        "outputId": "c8babe29-5c06-4d0f-8cfc-837348c41473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2120, 12544]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps to\n",
        "\n",
        "Load the dataset: train_iter and test_iter hold training and test data.\n",
        "Convert to map-style datasets: Make datasets compatible with random access (train_dataset and test_dataset).\n",
        "Split the training dataset:\n",
        "95% for training (split_train_).\n",
        "5% for validation (split_valid_).\n",
        "Prepare for GPU/CPU: Ensures that the training process utilizes GPU if available, otherwise defaults to CPU."
      ],
      "metadata": {
        "id": "mVZZFGkr37f6"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}