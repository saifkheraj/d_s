{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dash-core-components==2.0.0\n",
        "!pip install dash-table==5.0.0\n",
        "!pip install dash==2.9.3\n",
        "!pip install -Uqq dash-html-components==2.0.0\n",
        "!pip install -Uqq portalocker>=2.0.0\n",
        "!pip install -qq torchtext\n",
        "!pip install -qq torchdata\n",
        "!pip install -Uqq plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiT9dYHPuNGs",
        "outputId": "b945f1b3-5079-40d8-8159-6cf603291562"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: dash-core-components\n",
            "Successfully installed dash-core-components-2.0.0\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: dash-table\n",
            "Successfully installed dash-table-5.0.0\n",
            "Collecting dash==2.9.3\n",
            "  Downloading dash-2.9.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash==2.9.3) (3.1.0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash==2.9.3) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash==2.9.3)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.11/dist-packages (from dash==2.9.3) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash==2.9.3) (5.0.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.0.4->dash==2.9.3) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.0.4->dash==2.9.3) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.0.4->dash==2.9.3) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.0.4->dash==2.9.3) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.0.4->dash==2.9.3) (1.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash==2.9.3) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash==2.9.3) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.0.4->dash==2.9.3) (3.0.2)\n",
            "Downloading dash-2.9.3-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Installing collected packages: dash-html-components, dash\n",
            "Successfully installed dash-2.9.3 dash-html-components-2.0.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PkMTzLwbCU7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.0 torchtext==0.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R1XE3f9pue6h",
        "outputId": "9b1395de-911f-4fcd-bced-9fdeb7609083"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.20.5 torch-2.3.0 triton-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "603f42ade5894129a8aedd69d6ddffa0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq torchdata\n"
      ],
      "metadata": {
        "id": "j8JmZb3nCW5H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1+cpu torchvision==0.15.2+cpu torchtext==0.15.2+cpu --index-url https://download.pytorch.org/whl/cpu\n"
      ],
      "metadata": {
        "id": "w_60WI2tCZxL",
        "outputId": "3a2d299d-511f-4194-ce87-4cc41bfcec7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.0.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.0.1%2Bcpu-cp311-cp311-linux_x86_64.whl (195.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.15.2%2Bcpu-cp311-cp311-linux_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.15.2+cpu\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.15.2%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cpu) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cpu) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cpu) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cpu) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cpu) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cpu) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cpu) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cpu) (11.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2+cpu) (4.67.1)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2+cpu)\n",
            "  Downloading https://download.pytorch.org/whl/torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2+cpu) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cpu) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cpu) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cpu) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cpu) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cpu) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0\n",
            "    Uninstalling torch-2.3.0:\n",
            "      Successfully uninstalled torch-2.3.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.10.1\n",
            "    Uninstalling torchdata-0.10.1:\n",
            "      Successfully uninstalled torchdata-0.10.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1+cpu torchdata-0.6.1 torchtext-0.15.2+cpu torchvision-0.15.2+cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchdata",
                  "torchgen",
                  "torchtext"
                ]
              },
              "id": "ac0eab154af3432a97daf1dd076a91ab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "cFPgzXlat7UD"
      },
      "outputs": [],
      "source": [
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import accumulate\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from torchtext.datasets import AG_NEWS\n",
        "from IPython.display import Markdown as md\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import AG_NEWS\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.graph_objs as go\n",
        "import pickle\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(COST,ACC):\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    color = 'tab:red'\n",
        "    ax1.plot(COST, color=color)\n",
        "    ax1.set_xlabel('epoch', color=color)\n",
        "    ax1.set_ylabel('total loss', color=color)\n",
        "    ax1.tick_params(axis='y', color=color)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('accuracy', color=color)  # you already handled the x-label with ax1\n",
        "    ax2.plot(ACC, color=color)\n",
        "    ax2.tick_params(axis='y', color=color)\n",
        "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HeDBN7Y-w2bo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embdings(my_embdings,name,vocab):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "  # Plot the data points\n",
        "  ax.scatter(my_embdings[:,0], my_embdings[:,1], my_embdings[:,2])\n",
        "\n",
        "  # Label the points\n",
        "  for j, label in enumerate(name):\n",
        "      i=vocab.get_stoi()[label]\n",
        "      ax.text(my_embdings[j,0], my_embdings[j,1], my_embdings[j,2], label)\n",
        "\n",
        "  # Set axis labels\n",
        "  ax.set_xlabel('X Label')\n",
        "  ax.set_ylabel('Y Label')\n",
        "  ax.set_zlabel('Z Label')\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5WYBhRKSw3NJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def plot_tras(words, model):\n",
        "    # Tokenize the input words using a tokenizer function\n",
        "    tokens = tokenizer(words)\n",
        "\n",
        "    # Define the model's embedding dimension (d_model)\n",
        "    d_model = 100\n",
        "\n",
        "    # Convert the input words to a PyTorch tensor and move it to the specified device\n",
        "    x = torch.tensor(text_pipeline(words)).unsqueeze(0).to(device)\n",
        "\n",
        "    # Apply the model's embedding layer and scale the embeddings by sqrt(d_model)\n",
        "    x_ = model.emb(x) * math.sqrt(d_model)\n",
        "\n",
        "    # Apply the model's positional encoder to the embeddings\n",
        "    x = model.pos_encoder(x_)\n",
        "\n",
        "    # Extract projection weights for query, key, and value from the model's state_dict\n",
        "    q_proj_weight = model.state_dict()['transformer_encoder.layers.0.self_attn.in_proj_weight'][0:embed_dim].t()\n",
        "    k_proj_weight = model.state_dict()['transformer_encoder.layers.0.self_attn.in_proj_weight'][embed_dim:2*embed_dim].t()\n",
        "    v_proj_weight = model.state_dict()['transformer_encoder.layers.0.self_attn.in_proj_weight'][2*embed_dim:3*embed_dim].t()\n",
        "\n",
        "    # Calculate query (Q), key (K), and value (V) matrices\n",
        "    Q = (x @ q_proj_weight).squeeze(0)\n",
        "    K = (x @ k_proj_weight).squeeze(0)\n",
        "    V = (x @ v_proj_weight).squeeze(0)\n",
        "\n",
        "    # Calculate attention scores using dot-product attention\n",
        "    scores = Q @ K.T\n",
        "\n",
        "    # Set row and column labels for the attention matrix\n",
        "    row_labels = tokens\n",
        "    col_labels = row_labels\n",
        "\n",
        "    # Create a heatmap of the attention scores\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(scores.cpu().detach().numpy())\n",
        "    plt.yticks(range(len(row_labels)), row_labels)\n",
        "    plt.xticks(range(len(col_labels)), col_labels, rotation=90)\n",
        "    plt.title(\"Dot-Product Attention\")\n",
        "    plt.show()\n",
        "\n",
        "    # Apply softmax to the attention scores and create a heatmap\n",
        "    att = nn.Softmax(dim=1)(scores)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(att.cpu().detach().numpy())\n",
        "    plt.yticks(range(len(row_labels)), row_labels)\n",
        "    plt.xticks(range(len(col_labels)), col_labels, rotation=90)\n",
        "    plt.title(\"Scaled Dot-Product Attention\")\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate the attention head by multiplying softmax scores with values (V)\n",
        "    head = nn.Softmax(dim=1)(scores) @ V\n",
        "\n",
        "    # Visualize the embeddings and attention heads using t-SNE\n",
        "    tsne(x_, tokens, title=\"Embeddings\")\n",
        "    tsne(head, tokens, title=\"Attention Heads\")\n",
        "\n",
        "\n",
        "def tsne(embeddings, tokens, title=\"Embeddings\"):\n",
        "    # Initialize t-SNE with 2 components and a fixed random state\n",
        "    tsne = TSNE(n_components=2, random_state=0)\n",
        "\n",
        "    # Fit t-SNE to the embeddings (converting from GPU if necessary)\n",
        "    tsne_result = tsne.fit_transform(embeddings.squeeze(0).cpu().detach().numpy())\n",
        "\n",
        "    # Create a scatter plot of the t-SNE results\n",
        "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1])\n",
        "\n",
        "    # Set a title for the plot\n",
        "    plt.title(title)\n",
        "\n",
        "    # Add labels for each point in the scatter plot\n",
        "    for j, label in enumerate(tokens):\n",
        "        # Place the label text at the corresponding t-SNE coordinates\n",
        "        plt.text(tsne_result[j, 0], tsne_result[j, 1], label)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "64xGAuCfw7XJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_list_to_file(lst, filename):\n",
        "    \"\"\"\n",
        "    Save a list to a file using pickle serialization.\n",
        "\n",
        "    Parameters:\n",
        "        lst (list): The list to be saved.\n",
        "        filename (str): The name of the file to save the list to.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(lst, file)\n",
        "\n",
        "def load_list_from_file(filename):\n",
        "    \"\"\"\n",
        "    Load a list from a file using pickle deserialization.\n",
        "\n",
        "    Parameters:\n",
        "        filename (str): The name of the file to load the list from.\n",
        "\n",
        "    Returns:\n",
        "        list: The loaded list.\n",
        "    \"\"\"\n",
        "    with open(filename, 'rb') as file:\n",
        "        loaded_list = pickle.load(file)\n",
        "    return loaded_list"
      ],
      "metadata": {
        "id": "W_MUtQiPy-cm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Toy dataset\n",
        "These are essentially the same steps that you have done in the previous labs. However, let's have a brief explanation. The code defines a dataset, tokenizes the text data using a basic English tokenizer, creates a vocabulary from the tokenized data, and sets up a default index for handling unknown tokens.\n"
      ],
      "metadata": {
        "id": "2Q2CyaITzDd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    (1,\"Introduction to NLP\"),\n",
        "    (2,\"Basics of PyTorch\"),\n",
        "    (1,\"NLP Techniques for Text Classification\"),\n",
        "    (3,\"Named Entity Recognition with PyTorch\"),\n",
        "    (3,\"Sentiment Analysis using PyTorch\"),\n",
        "    (3,\"Machine Translation with PyTorch\"),\n",
        "    (1,\" NLP Named Entity,Sentiment Analysis,Machine Translation \"),\n",
        "    (1,\" Machine Translation with NLP \"),\n",
        "    (1,\" Named Entity vs Sentiment Analysis  NLP \"),\n",
        "    (3,\"he painted the car red\"),\n",
        "    (1,\"he painted the red car\")\n",
        "    ]\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for  _,text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(dataset), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "_YEXPUA6zCoL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the text processing pipeline with the tokenizer and vocabulary. The text and label pipelines will be used to process the raw data strings from the dataset iterators.\n",
        "\n",
        "The function text_pipeline will tokenize the input text, and vocab will then be applied to get the token indices. The label_pipeline will ensure that the labels start at zero.\n",
        "\n",
        "These pipelines are defined here for future use."
      ],
      "metadata": {
        "id": "x9W8unjezJzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_pipeline(x):\n",
        "  return vocab(tokenizer(x))\n",
        "\n",
        "def label_pipeline(x):\n",
        "   return int(x) - 1"
      ],
      "metadata": {
        "id": "7UfCyJuRzKMC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [torch.tensor([j for j in range(1,i)]) for i in range(2,10)]\n",
        "sequences"
      ],
      "metadata": {
        "id": "nr2BFKAczOeg",
        "outputId": "429fbf4c-506f-4c64-dae3-499dfa61b56f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1]),\n",
              " tensor([1, 2]),\n",
              " tensor([1, 2, 3]),\n",
              " tensor([1, 2, 3, 4]),\n",
              " tensor([1, 2, 3, 4, 5]),\n",
              " tensor([1, 2, 3, 4, 5, 6]),\n",
              " tensor([1, 2, 3, 4, 5, 6, 7]),\n",
              " tensor([1, 2, 3, 4, 5, 6, 7, 8])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function pad_sequence from torch.nn.utils.rnn in PyTorch is used to pad a sequence of tensors to the same length along a specified dimension. This function is commonly used when dealing with sequences of variable lengths, such as in natural language processing (NLP) tasks when working with tokenized sentences of different lengths.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "Input: pad_sequence takes a list of tensors as input, where each tensor represents a sequence. These sequences can have different lengths.\n",
        "\n",
        "Padding: The function pads the sequences with zeros (or another specified padding value) to make them all the same length. It pads sequences to match the length of the longest sequence in the list.\n",
        "\n",
        "Output: The output is a single tensor where all sequences are stacked along the specified dimension (by default, it's the first dimension). The result is a batch of sequences with the same length."
      ],
      "metadata": {
        "id": "sgy2RSZF_TPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "print(padded_sequences)"
      ],
      "metadata": {
        "id": "7y8zUr3y_ZFz",
        "outputId": "5450a8fd-f3c8-4798-a4b4-305ca02c1c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 2, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 2, 3, 0, 0, 0, 0, 0],\n",
            "        [1, 2, 3, 4, 0, 0, 0, 0],\n",
            "        [1, 2, 3, 4, 5, 0, 0, 0],\n",
            "        [1, 2, 3, 4, 5, 6, 0, 0],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 0],\n",
            "        [1, 2, 3, 4, 5, 6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TransformerEncoder is a stack of multiple TransformerEncoderLayers that process input sequences.\n",
        "\n",
        "How It Works\n",
        "Input Sequence: The encoder takes a sequence of words (converted into embeddings).\n",
        "\n",
        "Positional Encoding: Since transformers don't process words one by one,\n",
        "positional encoding is added to track word order.\n",
        "Pass Through Layers: The input sequence is passed through multiple\n",
        "\n",
        "TransformerEncoderLayers, each refining the understanding of the text.\n",
        "Final Output: The processed sequence is passed to the next part of the model (e.g., a classifier or decoder)."
      ],
      "metadata": {
        "id": "9bODA0ua_z7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer=nn.TransformerEncoderLayer(\n",
        "            d_model=3,\n",
        "            nhead=1,\n",
        "            dim_feedforward=1,\n",
        "            dropout=0,\n",
        "        )"
      ],
      "metadata": {
        "id": "RLxlDcyC_dJp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of transformers, your objective is to train the model to take an input sequence and effectively generate another sequence as its output, a fundamental task that underlies a wide range of natural language processing and sequence-to-sequence tasks."
      ],
      "metadata": {
        "id": "NosRnDYlBluZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter= AG_NEWS(split=\"train\")"
      ],
      "metadata": {
        "id": "IyXaDR8jB1P_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AG_NEWS dataset in torchtext does not support direct indexing like a list or tuple. It is not a random access dataset but rather an iterable dataset that needs to be used with an iterator. This approach is more effective for text data."
      ],
      "metadata": {
        "id": "pfb9JsIAEMyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y,text= next(iter(train_iter ))\n",
        "print(y,text)"
      ],
      "metadata": {
        "id": "xgMB-D7KBOww",
        "outputId": "f2578da4-4cd5-46fa-c376-202ef87a686b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
        "ag_news_label[y]"
      ],
      "metadata": {
        "id": "SAIJLBbGEo6A",
        "outputId": "2411fe32-23b2-4e92-fa93-9d5f17d95bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Business'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = len(set([label for (label, text) in train_iter ]))\n",
        "num_class"
      ],
      "metadata": {
        "id": "-hZPuH_AExZp",
        "outputId": "04c01c3f-6995-45d1-8dce-89b4881cf0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "MsCmKTYBEzOn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab([\"age\",\"hello\"])"
      ],
      "metadata": {
        "id": "n4yOnQmME6Tw",
        "outputId": "666036c2-e3cd-4f80-f7bf-4153c8527c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2120, 12544]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset preparation"
      ],
      "metadata": {
        "id": "OIHGPDWYFII9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert the dataset into map-style datasets and then perform a random split to create separate training and validation datasets. The training dataset will contain 95% of the samples, while the validation dataset will contain the remaining 5%. These datasets can be used for training and evaluating a machine learning model for text classification on the AG_NEWS dataset."
      ],
      "metadata": {
        "id": "wdUf9osBE_Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing iterators.\n",
        "train_iter, test_iter = AG_NEWS()\n",
        "\n",
        "# Convert the training and testing iterators to map-style datasets.\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "\n",
        "# Determine the number of samples to be used for training and validation (5% for validation).\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "\n",
        "# Randomly split the training dataset into training and validation datasets using `random_split`.\n",
        "# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n",
        "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
      ],
      "metadata": {
        "id": "0CwspdfXE71j"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "6EadYxg2FK7Y",
        "outputId": "a8938fea-0032-44c1-db9e-4a3c232b70da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}