{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwCAF_4WnGrm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM7UEy92nGrn"
      },
      "source": [
        "print(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXCwcSponGrp",
        "outputId": "300c438c-67d7-4eec-b03e-9761ced165b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello\n"
          ]
        }
      ],
      "source": [
        "print(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this lab, let's us the following libraries:\n",
        "\n",
        "- [`torch`](https://pytorch.org/): The core library for building and training neural network models in this project, including the implementation of Self-Attention mechanisms and Positional Encodings.\n",
        "- [`torch.nn`](https://pytorch.org/docs/stable/nn.html), [`torch.nn.functional`](https://pytorch.org/docs/stable/nn.functional.html): These PyTorch submodules are used to define the neural network layers and apply functions such as activations, which are essential in building the model architecture.\n",
        "- [`Levenshtein`](https://pypi.org/project/python-Levenshtein/): This library is used for calculating the Levenshtein distance, which can be useful for evaluating model performance in tasks like text generation or translation by measuring the difference between the predicted and actual text sequences.\n",
        "- [`get_tokenizer`](https://pytorch.org/text/stable/data_utils.html), [`build_vocab_from_iterator`](https://pytorch.org/text/stable/vocab.html) from `torchtext`: These functions are crucial for preprocessing text data, including tokenizing text into words or subwords and building a vocabulary from the dataset, which are foundational steps in preparing data for NLP models.\n"
      ],
      "metadata": {
        "id": "MgR85alqozFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "! pip install Levenshtein\n",
        "#! pip install matplotlib\n",
        "!pip install torch==2.3.0 torchtext==0.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zjExYuO4omC3",
        "outputId": "482544eb-fda6-462b-a43a-b9cff2e092e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein) (3.11.0)\n",
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchtext==0.18.0\n",
            "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m835.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
            "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchtext-0.18.0 triton-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "04d69ee0e8fe42a1abcc0079b1be11f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "\n",
        "from Levenshtein import distance\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlJowdNkorSH",
        "outputId": "da01aa6e-35ac-4956-fe28-bb342d33f466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device for training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "split = 'train'\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 3e-4\n",
        "batch_size = 64\n",
        "max_iters = 5000              # Maximum training iterations\n",
        "eval_interval = 200           # Evaluate model every 'eval_interval' iterations in the training loop\n",
        "eval_iters = 100              # When evaluating, approximate loss using 'eval_iters' batches\n",
        "\n",
        "# Architecture parameters\n",
        "max_vocab_size = 256          # Maximum vocabulary size\n",
        "vocab_size = max_vocab_size   # Real vocabulary size (e.g. BPE has a variable length, so it can be less than 'max_vocab_size')\n",
        "block_size = 16               # Context length for predictions\n",
        "n_embd = 32                   # Embedding size\n",
        "num_heads = 2                 # Number of head in multi-headed attention\n",
        "n_layer = 2                   # Number of Blocks\n",
        "ff_scale_factor = 4           # Note: The '4' magic number is from the paper: In equation 2 uses d_model=512, but d_ff=2048\n",
        "dropout = 0.0                 # Normalization using dropout# 10.788929 M parameters\n",
        "\n",
        "head_size = n_embd // num_heads\n",
        "assert (num_heads * head_size) == n_embd"
      ],
      "metadata": {
        "id": "MJfe5mX9o7Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embdings(my_embdings,name,vocab):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "  # Plot the data points\n",
        "  ax.scatter(my_embdings[:,0], my_embdings[:,1], my_embdings[:,2])\n",
        "\n",
        "  # Label the points\n",
        "  for j, label in enumerate(name):\n",
        "      i=vocab.get_stoi()[label]\n",
        "      ax.text(my_embdings[j,0], my_embdings[j,1], my_embdings[j,2], label)\n",
        "\n",
        "  # Set axis labels\n",
        "  ax.set_xlabel('X Label')\n",
        "  ax.set_ylabel('Y Label')\n",
        "  ax.set_zlabel('Z Label')\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ay5oVtLOt_2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = {\n",
        "    'le': 'the'\n",
        "    , 'chat': 'cat'\n",
        "    , 'est': 'is'\n",
        "    , 'sous': 'under'\n",
        "    , 'la': 'the'\n",
        "    , 'table': 'table'\n",
        "}"
      ],
      "metadata": {
        "id": "XKjG8ITqwKya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and sort the input vocabulary from the dictionary's keys\n",
        "vocabulary_in = sorted(list(set(dictionary.keys())))\n",
        "# Display the size and the sorted vocabulary for the input language\n",
        "print(f\"Vocabulary input ({len(vocabulary_in)}): {vocabulary_in}\")\n",
        "\n",
        "# Create and sort the output vocabulary from the dictionary's values\n",
        "vocabulary_out = sorted(list(set(dictionary.values())))\n",
        "# Display the size and the sorted vocabulary for the output language\n",
        "print(f\"Vocabulary output ({len(vocabulary_out)}): {vocabulary_out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ljAt_ODuDQi",
        "outputId": "eab599a4-c92d-4ab3-fbf2-a0dc9a821179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary input (6): ['chat', 'est', 'la', 'le', 'sous', 'table']\n",
            "Vocabulary output (5): ['cat', 'is', 'table', 'the', 'under']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - The tokenize function is responsible for breaking down a sentence into individual words.\n",
        " - The translate function uses this tokenize function to split the input sentence and then translates each word according to the dictionary. The translated words are concatenated to form the output sentence."
      ],
      "metadata": {
        "id": "a4UGSNq-wTvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a list of vocabulary words into one-hot encoded vectors\n",
        "def encode_one_hot(vocabulary):\n",
        "    vocabulary_size = len(vocabulary)  # Get the size of the vocabulary\n",
        "    one_hot = dict()  # Initialize a dictionary to hold our one-hot encodings\n",
        "    LEN = len(vocabulary)  # The length of each one-hot encoded vector will be equal to the vocabulary size\n",
        "\n",
        "    # Iterate over the vocabulary to create a one-hot encoded vector for each word\n",
        "    for i, key in enumerate(vocabulary):\n",
        "        one_hot_vector = torch.zeros(LEN)  # Start with a vector of zeros\n",
        "        one_hot_vector[i] = 1  # Set the i-th position to 1 for the current word\n",
        "        one_hot[key] = one_hot_vector  # Map the word to its one-hot encoded vector\n",
        "        print(f\"{key}\\t: {one_hot[key]}\")  # Print each word and its encoded vector\n",
        "\n",
        "    return one_hot  # Return the dictionary of words and their one-hot encoded vectors"
      ],
      "metadata": {
        "id": "5YVTtBDbwQXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the one-hot encoding function to the input vocabulary and store the result\n",
        "one_hot_in = encode_one_hot(vocabulary_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShcjKOdk6y9_",
        "outputId": "5839bc4d-93d9-4f5d-f761-6b4602836266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chat\t: tensor([1., 0., 0., 0., 0., 0.])\n",
            "est\t: tensor([0., 1., 0., 0., 0., 0.])\n",
            "la\t: tensor([0., 0., 1., 0., 0., 0.])\n",
            "le\t: tensor([0., 0., 0., 1., 0., 0.])\n",
            "sous\t: tensor([0., 0., 0., 0., 1., 0.])\n",
            "table\t: tensor([0., 0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the one-hot encoded input vocabulary and print each vector\n",
        "# This visualizes the one-hot representation for each word in the input vocabulary\n",
        "for k, v in one_hot_in.items():\n",
        "    print(f\"E_{{ {k} }} = \" , v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr8xBDtk61iQ",
        "outputId": "9d8cb506-1306-4261-f6ed-4e8b41e5ea75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E_{ chat } =  tensor([1., 0., 0., 0., 0., 0.])\n",
            "E_{ est } =  tensor([0., 1., 0., 0., 0., 0.])\n",
            "E_{ la } =  tensor([0., 0., 1., 0., 0., 0.])\n",
            "E_{ le } =  tensor([0., 0., 0., 1., 0., 0.])\n",
            "E_{ sous } =  tensor([0., 0., 0., 0., 1., 0.])\n",
            "E_{ table } =  tensor([0., 0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the one-hot encoding function to the output vocabulary and store the result\n",
        "# This time we're encoding the target language vocabulary\n",
        "one_hot_out = encode_one_hot(vocabulary_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NoRHEzp693z",
        "outputId": "91f227bf-0040-4741-9485-5f166287f7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\t: tensor([1., 0., 0., 0., 0.])\n",
            "is\t: tensor([0., 1., 0., 0., 0.])\n",
            "table\t: tensor([0., 0., 1., 0., 0.])\n",
            "the\t: tensor([0., 0., 0., 1., 0.])\n",
            "under\t: tensor([0., 0., 0., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decode_one_hot function is designed to decode a one-hot encoded vector back into the corresponding token (word). It does this by finding the token whose one-hot representation has the highest cosine similarity with the given vector, which is effectively just the dot product due to the nature of one-hot vectors."
      ],
      "metadata": {
        "id": "oPqBDjD67QH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_one_hot(one_hot, vector):\n",
        "    \"\"\"\n",
        "    Decode a one-hot encoded vector to find the best matching token in the vocabulary.\n",
        "    \"\"\"\n",
        "    best_key, best_cosine_sim = None, 0\n",
        "    for k, v in one_hot.items():  # Iterate over the one-hot encoded vocabulary\n",
        "        cosine_sim = torch.dot(vector, v)  # Calculate dot product (cosine similarity)\n",
        "        if cosine_sim > best_cosine_sim:  # If this is the best similarity we've found\n",
        "            best_cosine_sim, best_key = cosine_sim, k  # Update the best similarity and token\n",
        "    return best_key  # Return the token corresponding to the one-hot vector"
      ],
      "metadata": {
        "id": "wCQj-0Ex7OiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    Translate a sentence using matrix multiplication, treating the dictionaries as matrices.\n",
        "    \"\"\"\n",
        "    sentence_out = ''  # Initialize the output sentence\n",
        "    for token_in in tokenize(sentence):  # Tokenize the input sentence\n",
        "        q = one_hot_in[token_in]  # Find the one-hot vector for the token\n",
        "        out = q @ K.T @ V  # Multiply with the input and output matrices to find the translation\n",
        "        token_out = decode_one_hot(one_hot_out, out)  # Decode the output one-hot vector to a token\n",
        "        sentence_out += token_out + ' '  # Append the translated token to the output sentence\n",
        "    return sentence_out.strip()  # Return the translated sentence"
      ],
      "metadata": {
        "id": "3ItaJpYyJgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Screenshot 2025-01-16 153047.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "5ByyIVdcLlQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The attention mechanism allows the model to focus on relevant parts of a sentence, helping it understand the context of words.\n",
        "\n",
        "Key Steps in the Attention Mechanism\n",
        "Input Processing:\n",
        "\n",
        "An input sentence (e.g., \"The bank of the river was flooded\") is fed into the model.\n",
        "Each word in the sentence is tokenized and converted into an embedding vector.\n",
        "For each word (or token), three vectors are created by multiplying the embedding vector with three learned matrices:\n",
        "\n",
        "Query vector (Q)\n",
        "\n",
        "Key vector (K)\n",
        "\n",
        "Value vector (V)\n",
        "\n",
        "Generating Attention Scores:\n",
        "\n",
        "To determine how much attention each word should pay to other words, the model:\n",
        "Takes the query vector of the current word (e.g., \"bank\").\n",
        "Multiplies it with the key vectors of all other words in the sentence using a dot product to compute attention scores.\n",
        "A high attention score indicates that a word is highly relevant in the given context (e.g., \"river\" and \"flooded\" are highly relevant to \"bank\" in this example).\n",
        "\n",
        "Using Attention Scores:\n",
        "\n",
        "The attention scores are used to weigh the value vectors of the corresponding words.\n",
        "\n",
        "The model combines the weighted value vectors to produce a context-aware representation of the current word.\n",
        "For example, in the sentence \"The bank of the river was flooded,\" the attention mechanism helps the model understand that \"bank\" refers to a river bank and not a financial institution, based on its relationship with \"river\" and \"flooded.\"\n",
        "Understanding Query, Key, and Value Matrices\n",
        "\n",
        "Key Matrix (K):\n",
        "\n",
        "Learns distinguishing features of each word, helping the model compare words and identify relevant ones.\n",
        "\n",
        "Query Matrix (Q):\n",
        "\n",
        "Learns parameters that, when multiplied with key vectors, produce meaningful attention scores.\n",
        "\n",
        "Value Matrix (V):\n",
        "\n",
        "Stores foundational knowledge about each word (e.g., meanings of \"bank\") and is refined by attention scores to produce context-aware word representations.\n",
        "\n",
        "Purpose of the Attention Mechanism\n",
        "\n",
        "The attention mechanism allows the model to create a context-aware representation of each word in the sentence.\n",
        "\n",
        "This helps the model disambiguate words with multiple meanings (like \"bank\") by focusing on other relevant words in the context.\n",
        "\n",
        "The final output is a set of refined, context-aware vectors for each word, which the model uses for further tasks like translation or text generation."
      ],
      "metadata": {
        "id": "CL7BCvoy_0UB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJNNb_U1_z9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Purpose of the Key Matrix (K)\n",
        "The Key Matrix (W_K) is a learnable weight matrix in Transformer models.\n",
        "It transforms token embeddings into key vectors, which help assess the relevance of each word in the sentence.\n",
        "\n",
        "These key vectors are later used in the attention mechanism to compute attention scores.\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "#### Token Embeddings (X):\n",
        "\n",
        "Each word in the sentence is represented as an embedding vector (e.g., 3-dimensional).\n",
        "\n",
        "#### Key Matrix (W_K):\n",
        "\n",
        "A trainable matrix that enriches the embeddings. For example, we have 3×3 matrix, containing learnable weights.\n",
        "\n",
        "If word embeddings have 3 values per word, the Key Matrix must also have 3 input columns to properly transform these embeddings.\n",
        "This ensures that the embedding size aligns with the key transformation.\n",
        "\n",
        "#### Computing the Key Vector (K) for Each Token:\n",
        "\n",
        "Multiply the token embedding X by W_K. For each word ( 1 x 3 embedding  we take dot product with W_K which is 3 x 3) to produce K (1 x 3).\n",
        "\n",
        "The output K is still a 1×3 vector, but now enriched with additional information.\n",
        "\n",
        "#### Constructing the Final Key Matrix (K)\n",
        "\n",
        "We compute the key vector for each token in the sentence.\n",
        "Then, all key vectors are stacked into a final key matrix. Final Key matrix would be of size vocabsize x 3.\n",
        "\n",
        "Note: Dont confuse W_K with final key matrix K.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xMDP-qQMHmkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" Self attention head. This class implements a self-attention mechanism\n",
        "        which is a key component of transformer-based neural network architectures. \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()  # Initialize the superclass (nn.Module)\n",
        "        # Embedding layer to convert input token indices to vectors of fixed size (n_embd)\n",
        "        self.embedding = nn.Embedding(vocab_size, n_embd)\n",
        "\n",
        "        # Linear layers to compute the queries, keys, and values from the embeddings\n",
        "\n",
        "        self.key = nn.Linear(n_embd, n_embd, bias=False)\n",
        "        self.query = nn.Linear(n_embd, n_embd, bias=False)\n",
        "        self.value = nn.Linear(n_embd, n_embd, bias=False)\n",
        "\n",
        "    def attention(self, x):\n",
        "        embedded_x = self.embedding(x)\n",
        "        k = self.key(embedded_x)\n",
        "        q = self.query(embedded_x)\n",
        "        v = self.value(embedded_x)\n",
        "        # Attention score\n",
        "        w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5   # Query * Keys / normalization\n",
        "        w = F.softmax(w, dim=-1)  # Do a softmax across the last dimesion\n",
        "        return embedded_x,k,q,v,w\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded_x = self.embedding(x)\n",
        "        k = self.key(embedded_x)\n",
        "        q = self.query(embedded_x)\n",
        "        v = self.value(embedded_x)\n",
        "        # Attention score\n",
        "        w = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5   # Query * Keys / normalization\n",
        "        w = F.softmax(w, dim=-1)  # Do a softmax across the last dimesion\n",
        "        # Add weighted values\n",
        "        out = w @ v\n",
        "        return out"
      ],
      "metadata": {
        "id": "Ltdeo8tDKI8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    (1,\"Introduction to NLP\"),\n",
        "    (2,\"Basics of PyTorch\"),\n",
        "    (1,\"NLP Techniques for Text Classification\"),\n",
        "    (3,\"Named Entity Recognition with PyTorch\"),\n",
        "    (3,\"Sentiment Analysis using PyTorch\"),\n",
        "    (3,\"Machine Translation with PyTorch\"),\n",
        "    (1,\" NLP Named Entity,Sentiment Analysis,Machine Translation \"),\n",
        "    (1,\" Machine Translation with NLP \"),\n",
        "    (1,\" Named Entity vs Sentiment Analysis  NLP \"),\n",
        "    (3,\"he painted the car red\"),\n",
        "    (1,\"he painted the red car\")\n",
        "    ]"
      ],
      "metadata": {
        "id": "pztnAViuVHn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")  # Get a basic English tokenizer"
      ],
      "metadata": {
        "id": "DXjpun-pVKtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter):\n",
        "    \"\"\"Yield list of tokens in the dataset.\"\"\"\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(dataset), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])  # Set default index for unknown words"
      ],
      "metadata": {
        "id": "NSJP8fZUVOUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_pipeline(x):\n",
        "    \"\"\"Converts a text string to a list of token indices.\"\"\"\n",
        "    return vocab(tokenizer(x))  # Tokenize the input and map each token to its index in the vocabulary"
      ],
      "metadata": {
        "id": "-8dhzZ97Vg_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)  # Total number of tokens in the vocabulary\n",
        "n_embd = 3  # Dimension of the embedding space\n",
        "\n",
        "# Create the attention head with the integrated embedding layer\n",
        "attention_head = Head()"
      ],
      "metadata": {
        "id": "KaRyu6xeVjFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sentence to be tokenized and converted to indices\n",
        "my_tokens = 'he painted the car red'\n",
        "# Apply the text pipeline to the sentence to get token indices\n",
        "input_data = torch.tensor(text_pipeline(my_tokens), dtype=torch.long)\n",
        "\n",
        "# Print out the shape and the token indices tensor\n",
        "print(input_data.shape)\n",
        "print(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4Xar-ALVoSo",
        "outputId": "35dd4954-7f28-436b-f8f2-8b8978e3ef3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5])\n",
            "tensor([12, 13, 15, 11, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### As you can see above, we have sentence size of 5 and we also have tokens indices for all the words. Next we pass this input data to attention(to see current alignment score) which first calculates embedding so after embedding, data would be transformed to 5 x 3 (vocab size x embedding size). In this step we use dot product.\n",
        "\n",
        "#### Then we calculate key, query, and value once we get embedding from above steps for each word (5 x 3 matrix). Wk, Wq and Wv is of size 3 x 3. So when we take dot product data (5 x 3) with each weight, we will get 5 x 3 query, key and value. For example for key, each row contains respective key vector for first word. In this step as well we use dot product operation.\n",
        "\n",
        "### Once we have all the components, we calculate alignment score w. We use Query(5 x 3) and Key (5 x 3) , compute dot product between these two with normalization to calculate alignment scores. Note we need to transpose K to match dimensions. So the output of alignment score would be 5 x 5 . This alignment tells us word to word relationship.\n",
        "\n",
        "#### Then we normalize score using softmax function."
      ],
      "metadata": {
        "id": "hC5dWOdthIBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the tokenized input data through the embedding layer and the attention mechanism of the Head class\n",
        "embedded_x, k, q, v, w = attention_head.attention(input_data)\n",
        "\n",
        "# Print the size of the resulting embedded vector for verification\n",
        "print(embedded_x.shape)  # Should show the shape as [number of tokens, embedding dimension]\n",
        "print(\"embedded_x:\", embedded_x)  # The actual embedded representations of the input tokens"
      ],
      "metadata": {
        "id": "UHfCgHZ8g-0q",
        "outputId": "66fd69a1-e97f-4586-bc4a-7aaca4a3a987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "embedded_x: tensor([[ 0.6470,  0.4262,  1.0773],\n",
            "        [ 0.1049, -0.3996, -0.2484],\n",
            "        [-0.0993, -0.2529, -0.4103],\n",
            "        [ 0.4394, -0.1976,  0.1861],\n",
            "        [ 0.1175, -0.3715,  1.9094]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of the key, query, value, and attention weight matrices\n",
        "# This helps verify the dimensions are as expected for the attention calculations\n",
        "print(\"k:\", k.shape)  # The shape of the keys tensor\n",
        "print(\"q:\", q.shape)  # The shape of the queries tensor\n",
        "print(\"v:\", v.shape)  # The shape of the values tensor\n",
        "print(\"w:\", w.shape)  # The shape of the attention weights tensor"
      ],
      "metadata": {
        "id": "Bvqd98_HhEnH",
        "outputId": "7bd4a014-c1ac-408a-f537-7af98a0b0948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k: torch.Size([5, 3])\n",
            "q: torch.Size([5, 3])\n",
            "v: torch.Size([5, 3])\n",
            "w: torch.Size([5, 5])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}