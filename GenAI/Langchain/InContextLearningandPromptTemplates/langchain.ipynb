{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6bc3d2ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "56252efc9b104ce4aa1787133397b29d",
            "2f4f756710a64fa3b878b7a39dc96de2",
            "0a19445ef1134cfd8880c44671a83d62",
            "a8e9667c1cca46918313e08c9e475472",
            "48001ba5012941d889e710be9974212b",
            "3ede43d90b614bcca08c565bc2fb1632",
            "09cc869d7e874b0b832550e0eb06b5c9",
            "88ba49fe5dd14f3e9c99a9de838c587e",
            "b14443c54fa74723a654fa0138cd40b2",
            "c603e27d93c04ed89a864b6204055918",
            "bb046010a2db4916852c462848acbc36",
            "a77f79ed01fe41a592d9f0fdbb2f281d",
            "52db804a19a3473d984a0a1b76edd9ba",
            "a846c660cf8c4d9c94144e51ad4f2b6f",
            "f2718851097547a0adff289738a70126",
            "9fa5563bc7d74948ad0cda234549c226",
            "e915d39af0ee48af996cd04f3d78b2c3",
            "06c1e74fcd204feda4d98eaa1fe34882",
            "98305272bf224f7991e0b2ecf4189991",
            "77bde43a2ce54a2f9ae50b046c994f1d",
            "2e2752b3b5234ae3aa2a245a524f6e14",
            "94bc8f5066954275bd24cd0821c5a99b",
            "21d29e2cd6c0436091008028191d9506",
            "7671aaaa001d447f963ee961e9266111",
            "f473ba5b9c34410fac4d37ad8cdc5803",
            "a2f267ef5a664b4e95ea29a890f9569a",
            "eb4de848bc8a4402b401e32762c482a2",
            "597dd422fe694c30a2f2d761cf4ba2c4",
            "87741b4895324da98573701ba586ea88",
            "faa50a7054404af0b38b19815cc6d6ea",
            "9a01ebc865ea419e9f0d78914566e166",
            "21a7c3817b6b44918276d986057b3d8d",
            "a7cb7f3c59d34c2bb413ac9ea2b1efe1",
            "d8fa00cf1cb645bd8896790ebcab2c2b",
            "9b68f6ae479c4003808497bfb2bc7ddd",
            "b0085196ebd0464cb00069805e6f1196",
            "918b76359573465eac1e83ef6aa0d1fe",
            "7de949314e2c48269e417285ca79420b",
            "79fe21c498744ffe872dd4e9277a6431",
            "f71565ef8357408998d3f97f0df5220f",
            "466d48332c404cd9a0a7d9547755716e",
            "783cc1cd53c04d65856f8b2861c96099",
            "471217601cf54e04b18bb0547f1cf95e",
            "cd6a4f50f64f43968750dec004078cfb",
            "6230cdca6c844df1a3fe48373026bda0",
            "24bd013b20aa400590f2c561b7a0c4ff",
            "4c954adac3f543329d7213a0acd70fc7",
            "2cbf61c3cbd94736aa3d38265fec6daa",
            "591f22980b994d5bad7774e63322b2a2",
            "0f9bb78853d1474583ac0d8bcba97150",
            "1a6d31a82ac2436eabb166de9c7fd20e",
            "6952123a6c74421997d9459b331feed1",
            "4124259c9f2b4efea8e8492b4bd211fc",
            "455df7c611ba4dbd85fdcc095dc8bc4e",
            "207e4507b64843d3ab1f3de038172892",
            "d25fbbbbe7524322a740fd4bbf745a61",
            "5bf56f61fab94666b9446530156365dd",
            "f73f8bcb085649848bc0384ea821dc69",
            "f19eda33ae624b18843c1252040c5a64",
            "89c37f9166394e069a53a5b94d73abb2",
            "550949174ff34d2ca769076030b316ac",
            "6083b94a826145ffa0bdae8a9fc4d58d",
            "79f72f3bbd5c4d65ad3cf7a91e2454aa",
            "a0c8159cba054623b341db44bb0b8192",
            "8593fd6481464f2f916eacb15fad4d53",
            "f5c6a9355c3a4d2a9f722a84820db08d",
            "d5d520a15fc642dba0bb7805a856d59e",
            "0e98ae795944491a9e7735bbfeeb0e09",
            "d7e22c9c5f8242129a951ede666d5e7b",
            "944aa0bd911644b58a382e182dcf728b",
            "38cce495c29f41778bb556a8f1cea395",
            "6cdba82688f44b98af83248312dc8fb5",
            "942bbf09c5974c1a91a686f43844cdec",
            "ae765418a2884ebea662413df8bd3bc2",
            "ef3379e6b66c4b808676510d9e484988",
            "10877e2f77b34816b4818982306bf6a5",
            "ec63b9aa09e8408384b745ec0571ee16"
          ]
        },
        "id": "6bc3d2ee",
        "outputId": "0fa2ea48-3230-4bbe-bf1d-92c63316c819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.23 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56252efc9b104ce4aa1787133397b29d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a77f79ed01fe41a592d9f0fdbb2f281d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21d29e2cd6c0436091008028191d9506"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8fa00cf1cb645bd8896790ebcab2c2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6230cdca6c844df1a3fe48373026bda0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d25fbbbbe7524322a740fd4bbf745a61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5d520a15fc642dba0bb7805a856d59e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "<ipython-input-2-ad25475d42e7>:11: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=pipe)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install transformers datasets langchain\n",
        "!pip install langchain langchain-community\n",
        "\n",
        "\n",
        "# Load model & tokenizer\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0lrjAnpCkC1H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lrjAnpCkC1H",
        "outputId": "ec2552b3-be06-4db3-8f98-0ab82e0c1738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1e32f2a1718e>:13: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(prompt=prompt, llm=llm)\n",
            "<ipython-input-3-1e32f2a1718e>:17: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(chain.run({\"question\": question}))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bronchodilator\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Sample prompt setup\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "template = \"\"\"\n",
        "You are a clinical assistant AI. Answer the medical question accurately.\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "# Run a test example\n",
        "question = \"What is the treatment for mild asthma?\"\n",
        "print(chain.run({\"question\": question}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bk0UW-o_l3wP",
      "metadata": {
        "id": "bk0UW-o_l3wP"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "\n",
        "def llm_model(prompt_txt, model_name=\"google/flan-t5-base\", params=None):\n",
        "    # Default generation parameters\n",
        "    default_params = {\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"min_new_tokens\": 0,  # Not used directly\n",
        "        \"temperature\": 0.5,\n",
        "        \"top_p\": 0.9,\n",
        "        \"top_k\": 50\n",
        "    }\n",
        "\n",
        "    if params:\n",
        "        default_params.update(params)\n",
        "\n",
        "    # Hugging Face text2text-generation pipeline\n",
        "    pipe = pipeline(\n",
        "        task=\"text2text-generation\",\n",
        "        model=model_name,\n",
        "        max_new_tokens=default_params[\"max_new_tokens\"],\n",
        "        temperature=default_params[\"temperature\"],\n",
        "        top_p=default_params[\"top_p\"],\n",
        "        top_k=default_params[\"top_k\"],\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    # Wrap in LangChain's HuggingFace wrapper\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "    # Return response using LangChain's interface\n",
        "    response = llm.invoke(prompt_txt)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suCTkGHXmAxw",
      "metadata": {
        "id": "suCTkGHXmAxw"
      },
      "source": [
        "let's introduce a basic prompt that utilizes specific parameters to guide the language model's response. You'll then define a simple prompt and retrieve the model's response,\n",
        "\n",
        "The prompt used is \"The wind is\". Let the model generate itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Xi8xMEtDmCsD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi8xMEtDmCsD",
        "outputId": "72a214f0-e989-4bdb-f17d-12320b68d628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steroid\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "You are a clinical assistant AI.\n",
        "Question: What is the first-line treatment for mild hypertension?\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "print(llm_model(prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fb-5DUZqoDlq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb-5DUZqoDlq",
        "outputId": "5ae1fd48-fbf9-4e04-9092-51d1259801a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "What is the recommended antibiotic for a urinary tract infection in a non-pregnant woman?\n",
            "\n",
            "Response:\n",
            "acetaminophen\n",
            "\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    \"max_new_tokens\": 128,\n",
        "    \"min_new_tokens\": 10,  # Not used directly by HF, but kept for compatibility\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 0.2,\n",
        "    \"top_k\": 1\n",
        "}\n",
        "\n",
        "# ➤ Prompt example (you can change this)\n",
        "prompt = \"What is the recommended antibiotic for a urinary tract infection in a non-pregnant woman?\"\n",
        "\n",
        "# ➤ Generate response\n",
        "response = llm_model(prompt, params = params)\n",
        "\n",
        "# ➤ Output\n",
        "print(f\"Prompt:\\n{prompt}\\n\")\n",
        "print(f\"Response:\\n{response}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might notice that the response may appear truncated or incomplete. This is because you have set the `max_new_tokens,` which restricts the number of tokens the model can generate.\n",
        "\n",
        "Try to adjust the parameters and observe the difference in the response.\n"
      ],
      "metadata": {
        "id": "LJlV-DxaCNVa"
      },
      "id": "LJlV-DxaCNVa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot prompt\n",
        "\n",
        "Here is an example of a zero-shot prompt.\n",
        "\n",
        "Zero-shot learning is crucial for testing a model's ability to apply its pre-trained knowledge to new, unseen tasks without additional training. This capability is valuable for gauging the model's generalization skills.\n",
        "\n",
        "In this example, let's demonstrate a zero-shot learning scenario using a prompt that asks the model to classify a statement without any prior specific training on similar tasks. The prompt requests the model to assess the truthfulness of the statement: \"The Eiffel Tower is located in Berlin.\". After defining the prompt, you'll execute it with default parameters and print the response.\n",
        "\n",
        "This approach helps you understand how well the model can handle direct questions based on its underlying knowledge and reasoning abilities.\n"
      ],
      "metadata": {
        "id": "ifnFEc-wCQuX"
      },
      "id": "ifnFEc-wCQuX"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Classify the following statement as true or false:\n",
        "            'The Eiffel Tower is located in Berlin.'\n",
        "\n",
        "            Answer:\n",
        "\"\"\"\n",
        "response = llm_model(prompt, params = params)\n",
        "print(f\"prompt: {prompt}\\n\")\n",
        "print(f\"response : {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkCvDLwvCp3l",
        "outputId": "c8001ee2-4b3c-467d-f429-a39d894d96ba"
      },
      "id": "lkCvDLwvCp3l",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: Classify the following statement as true or false: \n",
            "            'The Eiffel Tower is located in Berlin.'\n",
            "\n",
            "            Answer:\n",
            "\n",
            "\n",
            "response : False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-shot prompt\n",
        "\n",
        "Here is a one-shot learning example where the model is given a single example to help guide its translation from English to French.\n",
        "\n",
        "The prompt provides a sample translation pairing, \"How is the weather today?\" translated to \"Comment est le temps aujourd'hui?\" This example serves as a guide for the model to understand the task context and desired format. The model is then tasked with translating a new sentence, \"Where is the nearest supermarket?\" without further guidance.\n"
      ],
      "metadata": {
        "id": "zJoYGGN3DXku"
      },
      "id": "zJoYGGN3DXku"
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"max_new_tokens\": 20,\n",
        "    \"temperature\": 0.1,\n",
        "}\n",
        "\n",
        "prompt = \"\"\"Here is an example of translating a sentence from English to French:\n",
        "\n",
        "            English: “How is the weather today?”\n",
        "            French: “Comment est le temps aujourd'hui?”\n",
        "\n",
        "            Now, translate the following sentence from English to French:\n",
        "\n",
        "            English: “Where is the nearest supermarket?”\n",
        "\n",
        "\"\"\"\n",
        "response = llm_model(prompt, params = params)\n",
        "print(f\"prompt: {prompt}\\n\")\n",
        "print(f\"response : {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEUY7UXJDaTo",
        "outputId": "49018110-dec8-48f4-f766-949caf957330"
      },
      "id": "wEUY7UXJDaTo",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: Here is an example of translating a sentence from English to French:\n",
            "\n",
            "            English: “How is the weather today?”\n",
            "            French: “Comment est le temps aujourd'hui?”\n",
            "            \n",
            "            Now, translate the following sentence from English to French:\n",
            "            \n",
            "            English: “Where is the nearest supermarket?”\n",
            "            \n",
            "\n",
            "\n",
            "response : « où est la supermarket nearest? »\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's response shows how it applies the structure and context provided by the initial example to translate the new sentence.\n",
        "\n",
        "Consider experimenting with different sentences or adjusting the parameters to see how these changes impact the model's translations.\n"
      ],
      "metadata": {
        "id": "1Un2LWw5DswK"
      },
      "id": "1Un2LWw5DswK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot prompt\n",
        "\n",
        "Here is an example of few-shot learning by classifying emotions from text statements.\n",
        "\n",
        "Let's provide the model with three examples, each labeled with an appropriate emotion—joy, frustration, and sadness—to establish a pattern or guideline on how to categorize emotions in statements.\n",
        "\n",
        "After presenting these examples, let's challenge the model with a new statement: \"That movie was so scary I had to cover my eyes.\" The task for the model is to classify the emotion expressed in this new statement based on the learning from the provided examples.\n"
      ],
      "metadata": {
        "id": "umbC1t8JDz95"
      },
      "id": "umbC1t8JDz95"
    },
    {
      "cell_type": "code",
      "source": [
        " #parameters  `max_new_tokens` to 10, which constrains the model to generate brief responses\n",
        "\n",
        "params = {\n",
        "    \"max_new_tokens\": 10,\n",
        "}\n",
        "\n",
        "prompt = \"\"\"Here are few examples of classifying emotions in statements:\n",
        "\n",
        "            Statement: 'I just won my first marathon!'\n",
        "            Emotion: Joy\n",
        "\n",
        "            Statement: 'I can't believe I lost my keys again.'\n",
        "            Emotion: Frustration\n",
        "\n",
        "            Statement: 'My best friend is moving to another country.'\n",
        "            Emotion: Sadness\n",
        "\n",
        "            Now, classify the emotion in the following statement:\n",
        "            Statement: 'That movie was so scary I had to cover my eyes.’\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "response = llm_model(prompt, params = params)\n",
        "print(f\"prompt: {prompt}\\n\")\n",
        "print(f\"response : {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RBluB13D2gr",
        "outputId": "0135c9b0-f716-4757-88bc-78f753f64b4a"
      },
      "id": "8RBluB13D2gr",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: Here are few examples of classifying emotions in statements:\n",
            "\n",
            "           Statement: 'I just won my first marathon!'\n",
            "           Emotion: Joy\n",
            "           \n",
            "           Statement: 'I can't believe I lost my keys again.'\n",
            "           Emotion: Frustration\n",
            "           \n",
            "           Statement: 'My best friend is moving to another country.'\n",
            "           Emotion: Sadness\n",
            "           \n",
            "           Now, classify the emotion in the following statement:\n",
            "           Statement: 'That movie was so scary I had to cover my eyes.’\n",
            "           \n",
            "\n",
            "\n",
            "\n",
            "response : Emotion: fear\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameters are set with `max_new_tokens` to 10, which constrains the model to generate brief responses, focusing on the essential output without elaboration.\n",
        "\n",
        "The model's response demonstrates its ability to use the provided few examples to understand and classify the emotion of the new statement effectively following the same pattern in examples.\n"
      ],
      "metadata": {
        "id": "szChtY7xD-0H"
      },
      "id": "szChtY7xD-0H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain-of-thought (CoT) prompting\n",
        "\n",
        "Here is an example of the Chain-of-Thought (CoT) prompting technique, designed to guide the model through a sequence of reasoning steps to solve a problem. In this example, the problem is a simple arithmetic question: “A store had 22 apples. They sold 15 apples today and received a new delivery of 8 apples. How many apples are there now?”\n",
        "\n",
        "The CoT technique involves structuring the prompt by instructing the model to “Break down each step of your calculation.” This encourages the model to include explicit reasoning steps, mimicking human-like problem-solving processes.\n"
      ],
      "metadata": {
        "id": "OtklVOBVEDRN"
      },
      "id": "OtklVOBVEDRN"
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"max_new_tokens\": 512,\n",
        "    \"temperature\": 0.5,\n",
        "}\n",
        "\n",
        "prompt = \"\"\"Consider the problem: 'A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples.\n",
        "            How many apples are there now?’\n",
        "\n",
        "            Break down each step of your calculation\n",
        "\n",
        "\"\"\"\n",
        "response = llm_model(prompt, params = params)\n",
        "print(f\"prompt: {prompt}\\n\")\n",
        "print(f\"response : {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6RlRaOZD6_4",
        "outputId": "d5a059e4-1617-4151-ec72-45cbffbd4b33"
      },
      "id": "Q6RlRaOZD6_4",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: Consider the problem: 'A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. \n",
            "            How many apples are there now?’\n",
            "\n",
            "            Break down each step of your calculation\n",
            "\n",
            "\n",
            "\n",
            "response : The store sold 15 apples and now has 22 - 15 = 14 apples. They have now 14 + 8 = 20 apples. The store has now sold 20 + 8 = 26 apples. The store has now sold 26 + 28 = 67 apples. The store has now sold 67 + 28 = 66 apples. The store has now sold 67 + 8 = 66 apples. The store has now sold 66 + 22 = 116 apples. The store has now sold 66 + 8 = 66 apples. The store has now sold 66 + 66 = 172 apples. The store has now sold 172 + 66 = 133 apples. The store has now sold 133 + 132 = 136 apples. The store has now sold 133 + 136 = 169 apples. The store has now sold 169 + 136 = 172 apples. The store has now sold 169 + 136 = 144 apples. The store has now sold 146 + 146 = 116 apples. The store has now sold 146 + 176 = 146 apples. The store has now sold 146 + 176 = 169 apples. The store has now sold 146 + 176 = 196 apples. The store has now sold 146 + 176 = 196 apples. The store has now sold 146 + 176 = 169 apples. The store has now sold 146 + 176 = 176 apples. The store has now sold 146 + 176 = 196 apples. The store has now sold 146 + 176 = 196 apples. The store has now sold 196 + 176 = 196 apples. The store has now sold 196 + 176 = 196 apples. The store has now sold 196 + 176 = 196 apples. The store has now sold 196 + 176 = 196 apples. The store has now sold 196 + 176 = 196 apples. The store has now sold 196 + 176 = 196 apples. The store has now sold 196 + 176 = 196 apples. The store has now sold 196 + 196 = 196 apples. The store has now sold 196 + 196 = 196 apples. The store has now sold 196 + 196 = 196 apples. The store has now sold 196 + 196 = 196 apples. The store has now sold 196 + 196 = 196 apples.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"max_new_tokens\": 128,\n",
        "    \"temperature\": 1.0,   # Neutral\n",
        "    \"top_p\": 1.0,\n",
        "    \"top_k\": 50\n",
        "}\n",
        "\n",
        "prompt = \"\"\"You are a helpful assistant.\n",
        "\n",
        "Solve this problem step-by-step:\n",
        "\n",
        "\"A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. How many apples are there now?\"\n",
        "\n",
        "Step-by-step solution:\"\"\"\n",
        "\n",
        "response = llm_model(prompt, params = params)\n",
        "print(f\"prompt: {prompt}\\n\")\n",
        "print(f\"response : {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ICr--JEjQg",
        "outputId": "eb40715f-b5ef-4e6c-dc9e-89edaa84fecf"
      },
      "id": "e7ICr--JEjQg",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: You are a helpful assistant.\n",
            "\n",
            "Solve this problem step-by-step:\n",
            "\n",
            "\"A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. How many apples are there now?\"\n",
            "\n",
            "Step-by-step solution:\n",
            "\n",
            "response : The store bought a total of 22 + 15 = 26 apples. The store now has 26 - 8 = 41 apples. The new delivery accounted for 41 + 8 = 93 apples. Therefore 22 apples + 41 = 93 apples. The answer: 93.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-consistency\n",
        "\n",
        "This example demonstrates the self-consistency technique in reasoning through multiple calculations for a single problem. The problem posed is: “When I was 6, my sister was half my age. Now I am 70, what age is my sister?”\n",
        "\n",
        "The prompt instructs, “Provide three independent calculations and explanations, then determine the most consistent result.” This encourages the model to engage in critical thinking and consistency checking, which are vital for complex decision-making processes.\n"
      ],
      "metadata": {
        "id": "mIjZ_ktfFAkN"
      },
      "id": "mIjZ_ktfFAkN"
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"max_new_tokens\": 512,\n",
        "}\n",
        "\n",
        "prompt = \"\"\"When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
        "See this as an example:When you were 10, your sister was 5 → age gap = 5 years Now you are 70 → sister = 70 - 5 = 65 years old.\n",
        "\n",
        "            Now Provide three independent calculations and explanations, then determine the most consistent result.\n",
        "\n",
        "\"\"\"\n",
        "response = llm_model(prompt, params = params)\n",
        "print(f\"prompt: {prompt}\\n\")\n",
        "print(f\"response : {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTdmZbuRFGxu",
        "outputId": "cba16e8d-3397-41d5-ad13-8a087ee62fff"
      },
      "id": "OTdmZbuRFGxu",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
            "See this as an example:When you were 10, your sister was 5 → age gap = 5 years Now you are 70 → sister = 70 - 5 = 65 years old. \n",
            "\n",
            "            Now Provide three independent calculations and explanations, then determine the most consistent result.\n",
            "\n",
            "\n",
            "\n",
            "response : Let x be the age gap between the two. When you were 6 years old, your sister was 6 * 6 = 24 years old. When you are 70, your sister is 70 - 24 = 25 years old. Then, when you are 70, your sister is 25 - 5 = 35 years old. Then, when you are 70, your sister is 35 - 5 = 34 years old. Then, when you are 70, your sister is 34 - 5 = 36 years old. Then, when you are 70, your sister is 36 - 5 = 35 years old. Then, when you are 70, your sister is 35 - 5 = 26 years old. Then, when you are 70, your sister is 26 - 5 = 26 years old. Then, when you are 70, your sister is 26 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 26 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are 70, your sister is 27 - 5 = 27 years old. Then, when you are\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model doesnt show good result. We will use google/flan-t5-xl"
      ],
      "metadata": {
        "id": "byUZMC5WFNqx"
      },
      "id": "byUZMC5WFNqx"
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"max_new_tokens\": 512,\n",
        "}\n",
        "\n",
        "prompt = \"\"\"When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
        "See this as an example:When you were 10, your sister was 5 → age gap = 5 years Now you are 70 → sister = 70 - 5 = 65 years old.\n",
        "\n",
        "            Now Provide three independent calculations and explanations, then determine the most consistent result.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = llm_model(prompt, model_name=\"google/flan-t5-xl\", params=params)\n",
        "\n",
        "print(f\"prompt:\\n{prompt}\\n\")\n",
        "print(f\"response:\\n{response}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "14d5a0925bf549cf8a95ecc03fb0aa98",
            "5e77b936c3804a798553db98fb8e95af",
            "48c6b4562c5947a09b8c677d732fd9d9",
            "25d78b134d9145768dc57848bd1f7c05",
            "dc3db37c0d94443bb5e5e6536c99d58a",
            "0000b270d0844fe3a2d70d03e8329179",
            "ff28a4c76bc64b0eabf82d01d06c4b1a",
            "af3320ec745e42a8ba417ec3e67b34af",
            "7502b7fc2dfb4a6bbf8bd2a707661c0a",
            "1b93488cae804693a8dd86654608c65a",
            "8503ef6e9af34258b296d83cc49369b3"
          ]
        },
        "id": "96NM0yrxr92K",
        "outputId": "d8829ae7-529b-425d-de16-ebd898623012"
      },
      "id": "96NM0yrxr92K",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14d5a0925bf549cf8a95ecc03fb0aa98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt:\n",
            "When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
            "See this as an example:When you were 10, your sister was 5 → age gap = 5 years Now you are 70 → sister = 70 - 5 = 65 years old. \n",
            "\n",
            "            Now Provide three independent calculations and explanations, then determine the most consistent result.\n",
            "\n",
            "\n",
            "\n",
            "response:\n",
            "Let X be the age of your sister when you were 6 years old. Now you are 70 and X = 6 years old. Now your sister is X - 6 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is 5 - 10 = 5 years old. Now your sister is X = 5 + 5 = 10 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now your sister is X = 10 - 5 = 5 years old. Now you are 70 and X = 10 years old. Now your sister is X = 10 - 5 = 5 years old. Now your sister is X = 10 - 5 = 5 years old.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's response shows that it provides three different calculations and explanations. Each calculation attempts to derive the sister's age using different logical approaches.\n",
        "\n",
        "Self-consistency can help identify the most accurate and reliable answer in scenarios where multiple plausible solutions exist.\n"
      ],
      "metadata": {
        "id": "bT96XEyGFP4v"
      },
      "id": "bT96XEyGFP4v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt template\n",
        "\n",
        "[Prompt template](https://python.langchain.com/v0.2/docs/concepts/#prompt-templates) is a key concept in langchain, it helps to translate user input and parameters into instructions for a language model. This can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based output.\n",
        "\n",
        "Use the `PromptTemplate` to create a template for a string-based prompt. In this template, you'll define two parameters: `adjective` and `content`. These parameters allow for the reuse of the prompt across different situations. For instance, to adapt the prompt to various contexts, simply pass the relevant values to these parameters.\n"
      ],
      "metadata": {
        "id": "PsoC2F5y3H1X"
      },
      "id": "PsoC2F5y3H1X"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7IXWjfRZ4ECv"
      },
      "id": "7IXWjfRZ4ECv",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "template = \"Tell me a {adjective} joke about {content}.\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "formatted_prompt = prompt.format(adjective=\"funny\", content=\"chickens\")\n",
        "print(formatted_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxhhM9uT4PEP",
        "outputId": "41e0bfdb-4ef9-4206-9c85-c9c5e6f53409"
      },
      "id": "mxhhM9uT4PEP",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me a funny joke about chickens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_prompt = prompt.format(adjective=\"funny\", content=\"chickens\")\n",
        "print(formatted_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17oAMHDC7YOX",
        "outputId": "903a9683-f5b3-47d4-e0f8-e11dadc3cb43"
      },
      "id": "17oAMHDC7YOX",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me a funny joke about chickens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_model(formatted_prompt, model_name=\"google/flan-t5-base\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIuVSxSD7iCZ",
        "outputId": "5521d365-7b44-478b-c601-8aa9d8e8d323"
      },
      "id": "BIuVSxSD7iCZ",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chickens are a poop poop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHzH28cq-OX5"
      },
      "id": "QHzH28cq-OX5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and use a PromptTemplate\n",
        "template = \"Tell me a {adjective} joke about {content}.\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "formatted_prompt = prompt.format(adjective=\"sarcastic\", content=\"doctors\")\n",
        "\n",
        "# Call the model\n",
        "response = llm_model(formatted_prompt)\n",
        "print(\"Prompt:\", formatted_prompt)\n",
        "print(\"Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW-7tFqr7kI7",
        "outputId": "3bc4a45d-c891-4405-aee4-3c16440b72c3"
      },
      "id": "EW-7tFqr7kI7",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Tell me a sarcastic joke about doctors.\n",
            "Response: if you spit on a doctor's head, he'll spit on you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Imports\n",
        "from transformers import pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n"
      ],
      "metadata": {
        "id": "Z0pvRH8T-aAv"
      },
      "id": "Z0pvRH8T-aAv",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define the model wrapper using HuggingFace\n",
        "def llm_model(model_name=\"google/flan-t5-base\", params=None):\n",
        "    default_params = {\n",
        "        \"max_new_tokens\": 128,\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.9,\n",
        "        \"top_k\": 50\n",
        "    }\n",
        "    if params:\n",
        "        default_params.update(params)\n",
        "\n",
        "    task = \"text2text-generation\" if \"t5\" in model_name.lower() else \"text-generation\"\n",
        "\n",
        "    pipe = pipeline(\n",
        "        task=task,\n",
        "        model=model_name,\n",
        "        tokenizer=model_name,\n",
        "        max_new_tokens=default_params[\"max_new_tokens\"],\n",
        "        temperature=default_params[\"temperature\"],\n",
        "        top_p=default_params[\"top_p\"],\n",
        "        top_k=default_params[\"top_k\"],\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    return HuggingFacePipeline(pipeline=pipe)\n"
      ],
      "metadata": {
        "id": "hwQ4eEwV-O5g"
      },
      "id": "hwQ4eEwV-O5g",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define the prompt template\n",
        "template = \"Tell me a {adjective} joke about {content}.\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "# 5. Create the LLMChain\n",
        "llm = llm_model()  # flan-t5-base by default\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "# 6. Run the chain\n",
        "response = llm_chain.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
        "print(\"Generated Joke:\\n\", response[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj7yCXNJ-Tke",
        "outputId": "8c5b3817-2c5e-4977-db3f-77f50dcbfa21"
      },
      "id": "Nj7yCXNJ-Tke",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Joke:\n",
            " I just can't figure out how to feed a chicken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_chain.invoke(input = {\"adjective\": \"sad\", \"content\": \"fish\"})\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "id": "bJtJYzju_bLd",
        "outputId": "e75bbc6d-628c-46ef-abb4-689e5f3a708f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bJtJYzju_bLd",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if you don't know the name of the fish, you're gonna know what to do.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 What is LLMChain in LangChain?\n",
        "\n",
        "## 🔍 Manual Prompting (The Basic Way)\n",
        "\n",
        "Manual prompting means you prepare your prompt manually as a string, insert values yourself, send it to the model, and get back a plain response.\n",
        "\n",
        "### Example:\n",
        "You write:\n",
        "> “Tell me a funny joke about chickens.”\n",
        "\n",
        "You send this directly to the model, and it returns a joke.\n",
        "\n",
        "### 🔹 Characteristics:\n",
        "- You manually insert values into the prompt (e.g., using `.format()` or f-strings)\n",
        "- You call the model directly with a plain string\n",
        "- It's simple and works fine for one-off tests\n",
        "- ❌ Not scalable\n",
        "- ❌ Not reusable or modular\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ What is `LLMChain`?\n",
        "\n",
        "`LLMChain` is a LangChain abstraction that combines:\n",
        "1. A **PromptTemplate** (e.g., `\"Tell me a {adjective} joke about {content}\"`)\n",
        "2. A **language model** (like Hugging Face, OpenAI, or Anthropic)\n",
        "\n",
        "LangChain automatically:\n",
        "- Fills in variables (e.g., `{\"adjective\": \"funny\", \"content\": \"chickens\"}`)\n",
        "- Generates the final prompt\n",
        "- Sends it to the model\n",
        "- Returns a **structured response**\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 Why Use `LLMChain`?\n",
        "\n",
        "### Advantages:\n",
        "- ✅ **Reusable** — Define once, use many times with different inputs\n",
        "- ✅ **Structured** — Pass inputs as dictionaries, get outputs with keys like `\"text\"`\n",
        "- ✅ **Composable** — Can be combined with memory, RAG, agents, etc.\n",
        "- ✅ **Clean Code** — No manual prompt formatting or string building\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 When to Use `LLMChain`\n",
        "\n",
        "| Use Case                        | Use `LLMChain`? |\n",
        "|---------------------------------|-----------------|\n",
        "| Quick one-off prompt            | ❌ Optional     |\n",
        "| Prompt testing/experimentation  | ✅ Yes          |\n",
        "| Chatbots or assistants          | ✅ Absolutely   |\n",
        "| Retrieval-augmented generation  | ✅ Yes          |\n",
        "| Tool-using agents               | ✅ Required     |\n",
        "| Building AI pipelines or apps   | ✅ Always       |\n",
        "\n",
        "---\n",
        "\n",
        "## 🔚 Summary\n",
        "\n",
        "- Manual prompting = simple but limited\n",
        "- `LLMChain` = structured, reusable, and essential for real apps\n",
        "- Use `LLMChain` when building anything beyond toy examples\n",
        "\n",
        "It’s the standard way to plug LLMs into real-world workflows in LangChain.\n",
        "\n"
      ],
      "metadata": {
        "id": "IIjPbXLn_Cct"
      },
      "id": "IIjPbXLn_Cct"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text summarization\n",
        "\n",
        "Here is a text summarization agent designed to help summarize the content you provide to the LLM.\n",
        "\n",
        "You can store the content to be summarized in a variable, allowing for repeated use of the prompt.\n"
      ],
      "metadata": {
        "id": "hRgxOJ8n_jrK"
      },
      "id": "hRgxOJ8n_jrK"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Your content\n",
        "content = \"\"\"\n",
        "The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation.\n",
        "Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems.\n",
        "For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion.\n",
        "Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers.\n",
        "These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\n",
        "\"\"\"\n",
        "\n",
        "# Use a better-structured prompt\n",
        "template = \"\"\"You are a helpful assistant.\n",
        "\n",
        "Summarize the following content in one sentence:\n",
        "\n",
        "{content}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Assuming you are using flan-t5-base or mistral llm\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm_model(model_name=\"google/flan-t5-base\"))\n",
        "\n",
        "# Invoke with structured input\n",
        "response = llm_chain.invoke({\"content\": content})\n",
        "\n",
        "# Print the result\n",
        "print(\"Summary:\\n\", response[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXDY8-Z-_TH6",
        "outputId": "85827d11-3088-494a-9610-9c81183bc5d9"
      },
      "id": "fXDY8-Z-_TH6",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Learn about the challenges of the 21st century.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question answering\n",
        "\n",
        "Here is a Q&A agent.\n",
        "\n",
        "This agent enables the LLM to learn from the provided content and answer questions based on what it has learned. Occasionally, if the LLM does not have sufficient information, it might generate a speculative answer. To manage this, you'll specifically instruct it to respond with \"Unsure about the answer\" if it is uncertain about the correct response.\n"
      ],
      "metadata": {
        "id": "MSGBSnEi__Ub"
      },
      "id": "MSGBSnEi__Ub"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Define content and question\n",
        "content = \"\"\"\n",
        "The solar system consists of the Sun, eight planets, their moons, dwarf planets, and smaller objects like asteroids and comets.\n",
        "The inner planets—Mercury, Venus, Earth, and Mars—are rocky and solid.\n",
        "The outer planets—Jupiter, Saturn, Uranus, and Neptune—are much larger and gaseous.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Which planets in the solar system are rocky and solid?\"\n",
        "\n",
        "# Properly structured prompt\n",
        "template = \"\"\"\n",
        "You are a helpful assistant.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Content:\n",
        "{content}\n",
        "\n",
        "If you're unsure about the answer, reply: \"Unsure about answer\".\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create prompt and chain\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm_model(model_name=\"google/flan-t5-base\"), output_key=\"answer\")\n",
        "\n",
        "# Run the chain\n",
        "response = llm_chain.invoke({\"question\": question, \"content\": content})\n",
        "\n",
        "# Output the result\n",
        "print(\"Answer:\\n\", response[\"answer\"])\n"
      ],
      "metadata": {
        "id": "RtT4mwmOACEo",
        "outputId": "8a615881-d619-48bb-a1a4-e0cfa9d00519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RtT4mwmOACEo",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            " Mercury, Venus, Earth, and Mars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text classification\n",
        "\n",
        "Here is a text classification agent designed to categorize text into predefined categories. This example employs zero-shot learning, where the agent classifies text without prior exposure to related examples.\n",
        "\n",
        "Can you revise it to the one-shot learning or few-shot learning in the exercises?\n"
      ],
      "metadata": {
        "id": "JVonyy5YArw3"
      },
      "id": "JVonyy5YArw3"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "text = \"\"\"\n",
        "The concert last night was an exhilarating experience with outstanding performances by all artists.\n",
        "\"\"\"\n",
        "\n",
        "categories = \"Entertainment, Food and Dining, Technology, Literature, Music.\"\n",
        "\n",
        "# Improved prompt structure\n",
        "template = \"\"\"\n",
        "You are a text classification assistant.\n",
        "\n",
        "Classify the following text into one of the given categories.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\n",
        "Categories:\n",
        "{categories}\n",
        "\n",
        "Category:\n",
        "\"\"\"\n",
        "\n",
        "# Create prompt template\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Create LLMChain with flan-t5-base\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm_model(model_name=\"google/flan-t5-base\"),\n",
        "    output_key=\"category\"\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "response = llm_chain.invoke({\"text\": text, \"categories\": categories})\n",
        "\n",
        "# Output the result\n",
        "print(\"Predicted Category:\", response[\"category\"])\n"
      ],
      "metadata": {
        "id": "-iHKA6-4ArOL",
        "outputId": "897f8427-ae8b-4df3-daac-ce986e65cbbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-iHKA6-4ArOL",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Category: Music\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-iCoFzsuAjtA"
      },
      "id": "-iCoFzsuAjtA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code generation\n",
        "\n",
        "Here is an example of an SQL code generation agent. This agent is designed to generate SQL queries based on given descriptions. It interprets the requirements from your input and translates them into executable SQL code.\n"
      ],
      "metadata": {
        "id": "HRmtetcdBM6t"
      },
      "id": "HRmtetcdBM6t"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Natural language description\n",
        "description = \"\"\"\n",
        "Retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days.\n",
        "The table 'purchases' contains a column 'purchase_date'.\n",
        "\"\"\"\n",
        "\n",
        "# Clear, structured prompt template\n",
        "template = \"\"\"\n",
        "You are an expert SQL generator.\n",
        "\n",
        "Task:\n",
        "Generate an SQL query based on the following description:\n",
        "\n",
        "{description}\n",
        "\n",
        "Only output the SQL query.\n",
        "\n",
        "SQL Query:\n",
        "\"\"\"\n",
        "\n",
        "# Create prompt and chain\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm_model(model_name=\"google/flan-t5-base\"), output_key=\"query\")\n",
        "\n",
        "# Run the chain\n",
        "response = llm_chain.invoke({\"description\": description})\n",
        "\n",
        "# Print output\n",
        "print(\"Generated SQL Query:\\n\", response[\"query\"])\n"
      ],
      "metadata": {
        "id": "IfHpAtjdBQvY",
        "outputId": "b93d853e-b243-474e-d8a1-e3fa4b0efc93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IfHpAtjdBQvY",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated SQL Query:\n",
            " result_name = 'customer' result_date = '31' if result_name == 'customer'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Role playing\n",
        "\n",
        "You can also configure the LLM to assume specific roles as defined by us, enabling it to follow predetermined rules and behave like a task-oriented chatbot.\n",
        "\n",
        "For example, the code below configures the LLM to act as a game master. In this role, the LLM answers questions about games while maintaining an engaging and immersive tone, enhancing the user experience.\n"
      ],
      "metadata": {
        "id": "DzFbIO2HCmPi"
      },
      "id": "DzFbIO2HCmPi"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Inputs\n",
        "role = \"game master\"\n",
        "tone = \"engaging and immersive\"\n",
        "question = \"Can you describe the scene as the players enter the haunted castle?\"\n",
        "\n",
        "# Clear prompt template\n",
        "template = \"\"\"\n",
        "You are an expert {role}.\n",
        "\n",
        "Task:\n",
        "I have the following question: \"{question}\"\n",
        "\n",
        "Your response should be written in a {tone} tone.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create prompt\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Initialize LLMChain with mixtral_llm (replace with your llm_model() if needed)\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm_model(model_name=\"google/flan-t5-base\"), output_key=\"answer\")\n",
        "\n",
        "# Run the chain\n",
        "response = llm_chain.invoke({\n",
        "    \"role\": role,\n",
        "    \"tone\": tone,\n",
        "    \"question\": question\n",
        "})\n",
        "\n",
        "# Print result\n",
        "print(\"Response:\\n\", response[\"answer\"])\n"
      ],
      "metadata": {
        "id": "s6uUJUE5Cr4w",
        "outputId": "8856140e-4948-4ebd-da9b-4ff28a196762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "s6uUJUE5Cr4w",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            " The players enter the castle and play the game of the spooky castle game.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56252efc9b104ce4aa1787133397b29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f4f756710a64fa3b878b7a39dc96de2",
              "IPY_MODEL_0a19445ef1134cfd8880c44671a83d62",
              "IPY_MODEL_a8e9667c1cca46918313e08c9e475472"
            ],
            "layout": "IPY_MODEL_48001ba5012941d889e710be9974212b"
          }
        },
        "2f4f756710a64fa3b878b7a39dc96de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ede43d90b614bcca08c565bc2fb1632",
            "placeholder": "​",
            "style": "IPY_MODEL_09cc869d7e874b0b832550e0eb06b5c9",
            "value": "config.json: 100%"
          }
        },
        "0a19445ef1134cfd8880c44671a83d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88ba49fe5dd14f3e9c99a9de838c587e",
            "max": 1404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b14443c54fa74723a654fa0138cd40b2",
            "value": 1404
          }
        },
        "a8e9667c1cca46918313e08c9e475472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c603e27d93c04ed89a864b6204055918",
            "placeholder": "​",
            "style": "IPY_MODEL_bb046010a2db4916852c462848acbc36",
            "value": " 1.40k/1.40k [00:00&lt;00:00, 119kB/s]"
          }
        },
        "48001ba5012941d889e710be9974212b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ede43d90b614bcca08c565bc2fb1632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09cc869d7e874b0b832550e0eb06b5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ba49fe5dd14f3e9c99a9de838c587e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b14443c54fa74723a654fa0138cd40b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c603e27d93c04ed89a864b6204055918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb046010a2db4916852c462848acbc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a77f79ed01fe41a592d9f0fdbb2f281d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52db804a19a3473d984a0a1b76edd9ba",
              "IPY_MODEL_a846c660cf8c4d9c94144e51ad4f2b6f",
              "IPY_MODEL_f2718851097547a0adff289738a70126"
            ],
            "layout": "IPY_MODEL_9fa5563bc7d74948ad0cda234549c226"
          }
        },
        "52db804a19a3473d984a0a1b76edd9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e915d39af0ee48af996cd04f3d78b2c3",
            "placeholder": "​",
            "style": "IPY_MODEL_06c1e74fcd204feda4d98eaa1fe34882",
            "value": "model.safetensors: 100%"
          }
        },
        "a846c660cf8c4d9c94144e51ad4f2b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98305272bf224f7991e0b2ecf4189991",
            "max": 990345061,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77bde43a2ce54a2f9ae50b046c994f1d",
            "value": 990345061
          }
        },
        "f2718851097547a0adff289738a70126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2752b3b5234ae3aa2a245a524f6e14",
            "placeholder": "​",
            "style": "IPY_MODEL_94bc8f5066954275bd24cd0821c5a99b",
            "value": " 990M/990M [00:04&lt;00:00, 226MB/s]"
          }
        },
        "9fa5563bc7d74948ad0cda234549c226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e915d39af0ee48af996cd04f3d78b2c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06c1e74fcd204feda4d98eaa1fe34882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98305272bf224f7991e0b2ecf4189991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77bde43a2ce54a2f9ae50b046c994f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e2752b3b5234ae3aa2a245a524f6e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94bc8f5066954275bd24cd0821c5a99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21d29e2cd6c0436091008028191d9506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7671aaaa001d447f963ee961e9266111",
              "IPY_MODEL_f473ba5b9c34410fac4d37ad8cdc5803",
              "IPY_MODEL_a2f267ef5a664b4e95ea29a890f9569a"
            ],
            "layout": "IPY_MODEL_eb4de848bc8a4402b401e32762c482a2"
          }
        },
        "7671aaaa001d447f963ee961e9266111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_597dd422fe694c30a2f2d761cf4ba2c4",
            "placeholder": "​",
            "style": "IPY_MODEL_87741b4895324da98573701ba586ea88",
            "value": "generation_config.json: 100%"
          }
        },
        "f473ba5b9c34410fac4d37ad8cdc5803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa50a7054404af0b38b19815cc6d6ea",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a01ebc865ea419e9f0d78914566e166",
            "value": 147
          }
        },
        "a2f267ef5a664b4e95ea29a890f9569a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21a7c3817b6b44918276d986057b3d8d",
            "placeholder": "​",
            "style": "IPY_MODEL_a7cb7f3c59d34c2bb413ac9ea2b1efe1",
            "value": " 147/147 [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "eb4de848bc8a4402b401e32762c482a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597dd422fe694c30a2f2d761cf4ba2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87741b4895324da98573701ba586ea88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faa50a7054404af0b38b19815cc6d6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a01ebc865ea419e9f0d78914566e166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21a7c3817b6b44918276d986057b3d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7cb7f3c59d34c2bb413ac9ea2b1efe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8fa00cf1cb645bd8896790ebcab2c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b68f6ae479c4003808497bfb2bc7ddd",
              "IPY_MODEL_b0085196ebd0464cb00069805e6f1196",
              "IPY_MODEL_918b76359573465eac1e83ef6aa0d1fe"
            ],
            "layout": "IPY_MODEL_7de949314e2c48269e417285ca79420b"
          }
        },
        "9b68f6ae479c4003808497bfb2bc7ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79fe21c498744ffe872dd4e9277a6431",
            "placeholder": "​",
            "style": "IPY_MODEL_f71565ef8357408998d3f97f0df5220f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b0085196ebd0464cb00069805e6f1196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_466d48332c404cd9a0a7d9547755716e",
            "max": 2537,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_783cc1cd53c04d65856f8b2861c96099",
            "value": 2537
          }
        },
        "918b76359573465eac1e83ef6aa0d1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_471217601cf54e04b18bb0547f1cf95e",
            "placeholder": "​",
            "style": "IPY_MODEL_cd6a4f50f64f43968750dec004078cfb",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 226kB/s]"
          }
        },
        "7de949314e2c48269e417285ca79420b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fe21c498744ffe872dd4e9277a6431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71565ef8357408998d3f97f0df5220f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "466d48332c404cd9a0a7d9547755716e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783cc1cd53c04d65856f8b2861c96099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "471217601cf54e04b18bb0547f1cf95e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6a4f50f64f43968750dec004078cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6230cdca6c844df1a3fe48373026bda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24bd013b20aa400590f2c561b7a0c4ff",
              "IPY_MODEL_4c954adac3f543329d7213a0acd70fc7",
              "IPY_MODEL_2cbf61c3cbd94736aa3d38265fec6daa"
            ],
            "layout": "IPY_MODEL_591f22980b994d5bad7774e63322b2a2"
          }
        },
        "24bd013b20aa400590f2c561b7a0c4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9bb78853d1474583ac0d8bcba97150",
            "placeholder": "​",
            "style": "IPY_MODEL_1a6d31a82ac2436eabb166de9c7fd20e",
            "value": "spiece.model: 100%"
          }
        },
        "4c954adac3f543329d7213a0acd70fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6952123a6c74421997d9459b331feed1",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4124259c9f2b4efea8e8492b4bd211fc",
            "value": 791656
          }
        },
        "2cbf61c3cbd94736aa3d38265fec6daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455df7c611ba4dbd85fdcc095dc8bc4e",
            "placeholder": "​",
            "style": "IPY_MODEL_207e4507b64843d3ab1f3de038172892",
            "value": " 792k/792k [00:00&lt;00:00, 47.9MB/s]"
          }
        },
        "591f22980b994d5bad7774e63322b2a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9bb78853d1474583ac0d8bcba97150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6d31a82ac2436eabb166de9c7fd20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6952123a6c74421997d9459b331feed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4124259c9f2b4efea8e8492b4bd211fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "455df7c611ba4dbd85fdcc095dc8bc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207e4507b64843d3ab1f3de038172892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d25fbbbbe7524322a740fd4bbf745a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bf56f61fab94666b9446530156365dd",
              "IPY_MODEL_f73f8bcb085649848bc0384ea821dc69",
              "IPY_MODEL_f19eda33ae624b18843c1252040c5a64"
            ],
            "layout": "IPY_MODEL_89c37f9166394e069a53a5b94d73abb2"
          }
        },
        "5bf56f61fab94666b9446530156365dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550949174ff34d2ca769076030b316ac",
            "placeholder": "​",
            "style": "IPY_MODEL_6083b94a826145ffa0bdae8a9fc4d58d",
            "value": "tokenizer.json: 100%"
          }
        },
        "f73f8bcb085649848bc0384ea821dc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f72f3bbd5c4d65ad3cf7a91e2454aa",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0c8159cba054623b341db44bb0b8192",
            "value": 2424064
          }
        },
        "f19eda33ae624b18843c1252040c5a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8593fd6481464f2f916eacb15fad4d53",
            "placeholder": "​",
            "style": "IPY_MODEL_f5c6a9355c3a4d2a9f722a84820db08d",
            "value": " 2.42M/2.42M [00:01&lt;00:00, 2.18MB/s]"
          }
        },
        "89c37f9166394e069a53a5b94d73abb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550949174ff34d2ca769076030b316ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6083b94a826145ffa0bdae8a9fc4d58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79f72f3bbd5c4d65ad3cf7a91e2454aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c8159cba054623b341db44bb0b8192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8593fd6481464f2f916eacb15fad4d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c6a9355c3a4d2a9f722a84820db08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5d520a15fc642dba0bb7805a856d59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e98ae795944491a9e7735bbfeeb0e09",
              "IPY_MODEL_d7e22c9c5f8242129a951ede666d5e7b",
              "IPY_MODEL_944aa0bd911644b58a382e182dcf728b"
            ],
            "layout": "IPY_MODEL_38cce495c29f41778bb556a8f1cea395"
          }
        },
        "0e98ae795944491a9e7735bbfeeb0e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cdba82688f44b98af83248312dc8fb5",
            "placeholder": "​",
            "style": "IPY_MODEL_942bbf09c5974c1a91a686f43844cdec",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d7e22c9c5f8242129a951ede666d5e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae765418a2884ebea662413df8bd3bc2",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef3379e6b66c4b808676510d9e484988",
            "value": 2201
          }
        },
        "944aa0bd911644b58a382e182dcf728b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10877e2f77b34816b4818982306bf6a5",
            "placeholder": "​",
            "style": "IPY_MODEL_ec63b9aa09e8408384b745ec0571ee16",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 188kB/s]"
          }
        },
        "38cce495c29f41778bb556a8f1cea395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cdba82688f44b98af83248312dc8fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942bbf09c5974c1a91a686f43844cdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae765418a2884ebea662413df8bd3bc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef3379e6b66c4b808676510d9e484988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10877e2f77b34816b4818982306bf6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec63b9aa09e8408384b745ec0571ee16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14d5a0925bf549cf8a95ecc03fb0aa98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e77b936c3804a798553db98fb8e95af",
              "IPY_MODEL_48c6b4562c5947a09b8c677d732fd9d9",
              "IPY_MODEL_25d78b134d9145768dc57848bd1f7c05"
            ],
            "layout": "IPY_MODEL_dc3db37c0d94443bb5e5e6536c99d58a"
          }
        },
        "5e77b936c3804a798553db98fb8e95af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0000b270d0844fe3a2d70d03e8329179",
            "placeholder": "​",
            "style": "IPY_MODEL_ff28a4c76bc64b0eabf82d01d06c4b1a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "48c6b4562c5947a09b8c677d732fd9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af3320ec745e42a8ba417ec3e67b34af",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7502b7fc2dfb4a6bbf8bd2a707661c0a",
            "value": 2
          }
        },
        "25d78b134d9145768dc57848bd1f7c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b93488cae804693a8dd86654608c65a",
            "placeholder": "​",
            "style": "IPY_MODEL_8503ef6e9af34258b296d83cc49369b3",
            "value": " 2/2 [00:00&lt;00:00,  2.22it/s]"
          }
        },
        "dc3db37c0d94443bb5e5e6536c99d58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0000b270d0844fe3a2d70d03e8329179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff28a4c76bc64b0eabf82d01d06c4b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af3320ec745e42a8ba417ec3e67b34af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7502b7fc2dfb4a6bbf8bd2a707661c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b93488cae804693a8dd86654608c65a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8503ef6e9af34258b296d83cc49369b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}