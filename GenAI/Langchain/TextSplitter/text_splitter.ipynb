{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "FmQR9RgKb6Hq",
   "metadata": {
    "id": "FmQR9RgKb6Hq"
   },
   "source": [
    "# **Apply Text Splitting Techniques to Enhance Model Responsiveness**\n",
    "\n",
    "In many data processing tasks, especially those involving large documents, breaking down text into smaller, more manageable chunks is essential. Text splitters are tools specifically designed to accomplish this, ensuring that lengthy texts are divided into coherent segments. This division is crucial for maintaining the integrity and readability of the information, making it easier to handle and process. Effective text splitting helps prevent overwhelming systems with large, unwieldy blocks of text and ensures that each segment remains meaningful and contextually relevant.\n",
    "\n",
    "The significance of text splitters becomes even more apparent in the context of retrieval-augmented generation (RAG). RAG involves fetching relevant pieces of information from a large dataset and using them to generate accurate and context-aware responses. Without properly split text, the retrieval process can become inefficient, potentially missing critical pieces of information or returning irrelevant data. By using text splitters to create well-defined chunks, the retrieval process can be streamlined, ensuring that the most relevant information is easily accessible. This not only enhances the efficiency of data retrieval but also improves the quality and relevance of the generated responses, making text splitters an important tool in the RAG workflow.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/3Y4eB0v7LXU5cSVbeN1b8A/text-splitter.png\" width=\"50%\" alt=\"langchain\">\n",
    "    <figcaption><a>source: DALL-E</a></figcaption>\n",
    "</figure>\n",
    "\n",
    "*   [`langchain`, `langchain-text-splitters`](https://www.langchain.com/) for using relevant features and text splitters from Langchain.\n",
    "*   [`lxml`](https://pypi.org/project/lxml/) for libxml2 and libxslt libraries, which is used for splitting html text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KXHQYcMNcG4h",
   "metadata": {
    "id": "KXHQYcMNcG4h"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e916ae",
   "metadata": {
    "id": "82e916ae"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"langchain==0.2.7\"\n",
    "!pip install \"langchain-core==0.2.20\"\n",
    "!pip install \"langchain-text-splitters==0.2.2\"\n",
    "!pip install \"lxml==5.2.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CmxKBQipcKp2",
   "metadata": {
    "id": "CmxKBQipcKp2"
   },
   "source": [
    "## Text splitters\n",
    "\n",
    "### Key parameters\n",
    "\n",
    "\n",
    "When using the splitter, you can customize several key parameters to fit your needs:\n",
    "- **separator**: Define the characters that will be used for splitting the text.\n",
    "- **chunk_size**: Specify the maximum size of your chunks to ensure they are as granular or broad as needed.\n",
    "- **chunk_overlap**: Maintain context between chunks by setting the `chunk_overlap` parameter, which determines the number of characters that overlap between consecutive chunks. This helps ensure that information isn't lost at the chunk boundaries.\n",
    "- **length_function**: Define how the length of chunks is calculated.\n",
    "\n",
    "### Prepare the document\n",
    "\n",
    "A long document has been prepared for this project to demonstrate the performance of each splitter. Run the following code to download it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hpq8uKgZcITH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpq8uKgZcITH",
    "outputId": "2247d083-fb23-433f-edb5-cb441fb0ce85"
   },
   "outputs": [],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/YRYau14UJyh0DdiLDdzFcA/companypolicies.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8gST8X6ceBD",
   "metadata": {
    "id": "f8gST8X6ceBD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b-mx-Lq-cgDH",
   "metadata": {
    "id": "b-mx-Lq-cgDH"
   },
   "source": [
    "Let's take a look at what the document looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qmacPgLHcfHY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmacPgLHcfHY",
    "outputId": "ec96417e-2561-4510-bd45-a8cd049cac0d"
   },
   "outputs": [],
   "source": [
    "# This is a long document you can split up.\n",
    "with open(\"companypolicies.txt\") as f:\n",
    "    companypolicies = f.read()\n",
    "print(companypolicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0oPcSiu3cptB",
   "metadata": {
    "id": "0oPcSiu3cptB"
   },
   "source": [
    "It is a long document about a company's policies.\n",
    "\n",
    "### Document object\n",
    "\n",
    "Before introducing the splitters, let's take a look at the document object in LangChain, which is a data structure used to represent and manage text data in RAG process.\n",
    "\n",
    "A Document object in LangChain contains information about some data. It has two attributes:\n",
    "\n",
    "- `page_content: str`: The content of this document. Currently is only a string.\n",
    "- `metadata: dict`: Arbitrary metadata associated with this document. Can track the document id, file name, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uHou88pccn6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHou88pccn6b",
    "outputId": "7581b2fc-8b66-4f7d-a0ab-5bf018a965be"
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "Document(page_content=\"\"\"Python is an interpreted high-level general-purpose programming language.\n",
    "                        Python's design philosophy emphasizes code readability with its notable use of significant indentation.\"\"\",\n",
    "         metadata={\n",
    "             'my_document_id' : 234234,\n",
    "             'my_document_source' : \"About Python\",\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Khvxi25Tds-r",
   "metadata": {
    "id": "Khvxi25Tds-r"
   },
   "source": [
    "### Split by Character\n",
    "\n",
    "This is the simplest method, which splits the text based on characters (by default `\"\\n\\n\"`) and measures chunk length by the number of characters.\n",
    "- **How the text is split**: By single character.\n",
    "- **How the chunk size is measured**: By number of characters.\n",
    "\n",
    "\n",
    "\n",
    "In the following code, you will use `CharacterTextSplitter` to split the document by character.\n",
    "- Separator: Set to `''`, meaning that any character can act as a separator once the chunk size reaches the set limit.\n",
    "- Chunk size: Set to `200`, meaning that once a chunk reaches 200 characters, it will be split.\n",
    "- Chunk overlap: Set to `20`, meaning there will be `20` characters overlapping between chunks.\n",
    "- Length function: Set to `len`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NJIl4zGzdnC0",
   "metadata": {
    "id": "NJIl4zGzdnC0"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-Nn2mIJed1q_",
   "metadata": {
    "id": "-Nn2mIJed1q_"
   },
   "source": [
    "You will use `split_text` function to operate the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0pImnNI0dzzF",
   "metadata": {
    "id": "0pImnNI0dzzF"
   },
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(companypolicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9x1soOAhd4sz",
   "metadata": {
    "id": "9x1soOAhd4sz"
   },
   "source": [
    "Let's take a look how the document has been split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s-1xSmxId575",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-1xSmxId575",
    "outputId": "93540611-d404-4950-8601-d37ff53bfafa"
   },
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eMtC4jd8d-OK",
   "metadata": {
    "id": "eMtC4jd8d-OK"
   },
   "source": [
    "After the split, you'll see that the document has been divided into multiple chunks, with some character overlaps between the chunks.\n",
    "\n",
    "You can see how many chunks you get.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SW7-h6Ukd9sT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SW7-h6Ukd9sT",
    "outputId": "8997adc5-9285-4ada-d8b3-d30ae7f3edf7"
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oO8vHvKueZ0X",
   "metadata": {
    "id": "oO8vHvKueZ0X"
   },
   "source": [
    " got `87` chunks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eABQrAjNedS4",
   "metadata": {
    "id": "eABQrAjNedS4"
   },
   "source": [
    "You can also use the following code to add metadata to the text, forming it into a `document` object using LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3kAxPKueho09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "3kAxPKueho09",
    "outputId": "c048bdef-38b5-49d1-c37c-f33ba8d9f585"
   },
   "outputs": [],
   "source": [
    "companypolicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mO5dLcqbeb1A",
   "metadata": {
    "id": "mO5dLcqbeb1A"
   },
   "outputs": [],
   "source": [
    "texts = text_splitter.create_documents([companypolicies], metadatas=[{\"document\":\"Company Policies\"}])  # pass the metadata as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JNZTi8DjjHVE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNZTi8DjjHVE",
    "outputId": "899111dc-3f7f-42ec-945a-24f689c3c48b"
   },
   "outputs": [],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gvDOy0LTjMNh",
   "metadata": {
    "id": "gvDOy0LTjMNh"
   },
   "source": [
    "### Recursively Split by Character\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters, and it tries to split on them in order until the chunks are small enough. The default list is `[\"\\n\\n\", \"\\n\", \" \", \"\"]`.\n",
    "\n",
    "It processes the large text by attempting to split it by the first character, `\\n\\n`. If the first split by \\n\\n results in chunks that are still too large, it moves to the next character, `\\n`, and attempts to split by it. This process continues through the list of characters until the chunks are less than the specified chunk size.\n",
    "\n",
    "This method aims to keep all paragraphs (then sentences, then words) together as much as possible, as these are generally the most semantically related pieces of text.\n",
    "\n",
    "- **How the text is split**: by list of characters.\n",
    "- **How the chunk size is measured**: by number of characters.\n",
    "\n",
    "The `RecursiveCharacterTextSplitter` class from LangChain is used to implement it.\n",
    "- You use the default separator list, which is `[\"\\n\\n\", \"\\n\", \" \", \"\"]`.\n",
    "- Chunk size is set to `100`.\n",
    "- Chunk overlap is set to `20`.\n",
    "- And the length function is `len`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G-BP0x-ijJyD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-BP0x-ijJyD",
    "outputId": "346b8ca4-9c5f-41d7-9ecf-99dbe0ce2fac"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.create_documents([companypolicies])\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2WbJr-D0jdAh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WbJr-D0jdAh",
    "outputId": "a9f30e5b-1ed9-4f29-8495-b631de207f3f"
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2wc405yTjd23",
   "metadata": {
    "id": "2wc405yTjd23"
   },
   "source": [
    "215 chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oMrCaOGZbAVk",
   "metadata": {
    "id": "oMrCaOGZbAVk"
   },
   "source": [
    "### Split Code\n",
    "\n",
    "The `CodeTextSplitter` allows you to split your code, supporting multiple programming languages. It is based on the `RecursiveCharacterTextSplitter` strategy. Simply import enum `Language` and specify the language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c_UKSEGcjfbb",
   "metadata": {
    "id": "c_UKSEGcjfbb"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cb5fHvFxbT1A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cb5fHvFxbT1A",
    "outputId": "792ea7a7-e047-4788-8157-4bc1a2ccf931"
   },
   "outputs": [],
   "source": [
    "## list it supports\n",
    "[e.value for e in Language]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jEpXitf_baKo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEpXitf_baKo",
    "outputId": "4ff6d388-b347-4743-e3f4-ebb1c73d0b73"
   },
   "outputs": [],
   "source": [
    "#Use the following code to see what default separators it uses, for example, for Python.\n",
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KNnvcE2Hbh6A",
   "metadata": {
    "id": "KNnvcE2Hbh6A"
   },
   "source": [
    "#### Python\n",
    "\n",
    "The following demonstrates how to split Python code using the `RecursiveCharacterTextSplitter` class.\n",
    "\n",
    "The main difference between splitting code and using the original `RecursiveCharacterTextSplitter` is that you need to call `.from_language` after the `RecursiveCharacterTextSplitter` and specify the `language`. The other parameter settings remain the same as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wQisGJapblyR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQisGJapblyR",
    "outputId": "d1014586-b5be-42cb-db35-164daf4e2efb"
   },
   "outputs": [],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "    def hello_world():\n",
    "        print(\"Hello, World!\")\n",
    "\n",
    "    # Call the function\n",
    "    hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ILRQXhJ2bp1f",
   "metadata": {
    "id": "ILRQXhJ2bp1f"
   },
   "source": [
    "#### Javascript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58PYJi0Zbq_L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58PYJi0Zbq_L",
    "outputId": "0d436092-55f5-4c12-cacd-3902c6c5cc55"
   },
   "outputs": [],
   "source": [
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.JS)\n",
    "JS_CODE = \"\"\"\n",
    "    function helloWorld() {\n",
    "      console.log(\"Hello, World!\");\n",
    "    }\n",
    "\n",
    "    // Call the function\n",
    "    helloWorld();\n",
    "\"\"\"\n",
    "\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "js_docs = js_splitter.create_documents([JS_CODE])\n",
    "js_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AzHVcUypbwsw",
   "metadata": {
    "id": "AzHVcUypbwsw"
   },
   "source": [
    "### Markdown Header Text Splitter\n",
    "\n",
    "As mentioned, chunking often aims to keep text with a common context together. With this in mind, you might want to specifically honor the structure of the document itself. For example, a Markdown file is organized by headers. Creating chunks within specific header groups is an intuitive approach.\n",
    "\n",
    "To address this challenge, you can use `MarkdownHeaderTextSplitter`. This splitter will divide a Markdown file based on a specified set of headers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3rRhpsjjbubT",
   "metadata": {
    "id": "3rRhpsjjbubT"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "btIWDsAjcSdo",
   "metadata": {
    "id": "btIWDsAjcSdo"
   },
   "outputs": [],
   "source": [
    "md = \"# Foo\\n\\n## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n### Boo \\n\\nHi this is Lance \\n\\n## Baz\\n\\nHi this is Molly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K3rmMoyccTvb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3rmMoyccTvb",
    "outputId": "8eac7b62-c6ed-46cc-e11f-ccf443af512a"
   },
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(md)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clZExJeOcsVS",
   "metadata": {
    "id": "clZExJeOcsVS"
   },
   "source": [
    "From the split results, you can see that the Markdown file is divided into several chunks formatted as document objects. The `page_content` contains the text under the headings, and the `metadata` contains the header information corresponding to the `page_content`.\n",
    "\n",
    "If you want the headers appears in the page_content as well, you can specify `strip_headers=False` when you call the `MarkdownHeaderTextSplitter`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FfsZr2fPcwAa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfsZr2fPcwAa",
    "outputId": "e82e1d0d-869b-4a54-f2c3-bf1294b3dcae"
   },
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "md_header_splits = markdown_splitter.split_text(md)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fJrGgCcrdssG",
   "metadata": {
    "id": "fJrGgCcrdssG"
   },
   "source": [
    "### Split by HTML\n",
    "\n",
    "#### Split by HTML header\n",
    "\n",
    "Similar in concept to the `MarkdownHeaderTextSplitter`, the HTMLHeaderTextSplitter is a \"structure-aware\" chunker that splits text at the element level and adds metadata for each header \"relevant\" to any given chunk. It can return chunks element by element or combine elements with the same metadata, with the objectives of (a) keeping related text grouped (more or less) semantically and (b) preserving context-rich information encoded in document structures. It can be used with other text splitters as part of a chunking pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yFPbR0w0donF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFPbR0w0donF",
    "outputId": "6efc75e6-835f-4a5e-e848-caba13eb59ed"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "html_string = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>Foo</h1>\n",
    "            <p>Some intro text about Foo.</p>\n",
    "            <div>\n",
    "                <h2>Bar main section</h2>\n",
    "                <p>Some intro text about Bar.</p>\n",
    "                <h3>Bar subsection 1</h3>\n",
    "                <p>Some text about the first subtopic of Bar.</p>\n",
    "                <h3>Bar subsection 2</h3>\n",
    "                <p>Some text about the second subtopic of Bar.</p>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h2>Baz</h2>\n",
    "                <p>Some text about Baz</p>\n",
    "            </div>\n",
    "            <br>\n",
    "            <p>Some concluding text about Foo</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qJb5XoF5eJsY",
   "metadata": {
    "id": "qJb5XoF5eJsY"
   },
   "source": [
    "From the split results, you can see that the context under the headings is extracted and put in the `page_content` parameter. The `metatdata` contains the header information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UNwbn772eUzP",
   "metadata": {
    "id": "UNwbn772eUzP"
   },
   "source": [
    "#### Split by HTML section\n",
    "\n",
    "Similar to the `HTMLHeaderTextSplitter`, the `HTMLSectionSplitter` is also a \"structure-aware\" chunker that splits text section by section based on headings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0oR2Ch6QeJHR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0oR2Ch6QeJHR",
    "outputId": "5b867f5d-0581-44d6-fb09-1a74ddca16e1"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>Foo</h1>\n",
    "            <p>Some intro text about Foo.</p>\n",
    "            <div>\n",
    "                <h2>Bar main section</h2>\n",
    "                <p>Some intro text about Bar.</p>\n",
    "                <h3>Bar subsection 1</h3>\n",
    "                <p>Some text about the first subtopic of Bar.</p>\n",
    "                <h3>Bar subsection 2</h3>\n",
    "                <p>Some text about the second subtopic of Bar.</p>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h2>Baz</h2>\n",
    "                <p>Some text about Baz</p>\n",
    "            </div>\n",
    "            <br>\n",
    "            <p>Some concluding text about Foo</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [(\"h1\", \"Header 1\"), (\"h2\", \"Header 2\"), (\"h3\", \"Header 3\")]\n",
    "\n",
    "html_splitter = HTMLSectionSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
