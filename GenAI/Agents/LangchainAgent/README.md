# üß† How the LangChain ReAct Agent Works (Step-by-Step Pipeline)

This document explains **how a LangChain ReAct agent works under the hood** ‚Äî including how prompts are built, how OpenAI processes them, and how LangChain handles tool execution and reasoning.

---

## üèóÔ∏è Step 1: Prompt Construction in the Backend

When the user submits a query like:

> "Compare the 2024 revenue of Google and Amazon."

LangChain uses a **ReAct prompt template**, either from LangChain Hub or a fallback like:

```text
Answer the following questions as best you can. You have access to the following tools:

{tools}

Use the following format:

Question: the input question
Thought: reason step by step
Action: the action to take, must be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (repeat Thought/Action/Input/Observation as needed)
Thought: I now know the final answer
Final Answer: the final answer

Begin!

Question: {input}
Thought: {agent_scratchpad}
```

### üìå Example Instantiated Prompt

```text
Question: Compare the 2024 revenue of Google and Amazon.
Thought:
```

LangChain fills in this template with the user query, tool names, and previous thoughts/actions (if any).

---

## üì§ Step 2: Sending Prompt to OpenAI

LangChain sends this prompt to the **OpenAI Completion API** (e.g., GPT-3.5):

```python
llm = OpenAI(temperature=0.1)
output = llm(prompt)
```

### ü§ñ GPT Output Example:

```text
Thought: I should search the 2024 revenue for both Google and Amazon.
Action: tavily_search_results_json
Action Input: 2024 revenue of Google and Amazon
```

This output is plain text. GPT "thinks" and "decides" what tool to use and what input to give it.

---

## ‚öôÔ∏è Step 3: LangChain Parses the Output

LangChain **parses the raw text output** to extract:

* `Thought`
* `Action`
* `Action Input`

Then it checks whether the Action name is a valid tool.

---

## üîß Step 4: Tool Execution

If a tool is mentioned (e.g., `tavily_search_results_json`), LangChain runs:

```python
tool_result = tool.invoke(action_input)
```

This might use the **Tavily API** to get real-time search results.

### üìÑ Observation Example:

```json
[
  { "title": "Amazon 2024 Revenue Report", "content": "$574B", "url": "..." },
  { "title": "Alphabet 2024 Results", "content": "$296B", "url": "..." }
]
```

---

## üßæ Step 5: Update Scratchpad

LangChain builds a new prompt:

```text
Question: Compare the 2024 revenue of Google and Amazon.

Thought: I should search the 2024 revenue for both Google and Amazon.
Action: tavily_search_results_json
Action Input: 2024 revenue of Google and Amazon
Observation: Amazon made $574B; Google made $296B.

Thought:
```

This updated prompt is sent **back to OpenAI** to continue reasoning.

---

## üîÅ Step 6: Loop Until Final Answer

The cycle continues:

* New prompt ‚Üí LLM ‚Üí New Action ‚Üí Tool ‚Üí Observation ‚Üí Repeat

Until the model outputs:

```text
Thought: I now know the final answer
Final Answer: Amazon earned $574B, while Google earned $296B in 2024.
```

LangChain stops execution and returns this to the user.

---

## üß† Summary of Roles

| Component            | Role                                                         |
| -------------------- | ------------------------------------------------------------ |
| Prompt Template      | Provides structured thinking pattern                         |
| OpenAI               | Generates thoughts, actions, and final answers               |
| LangChain            | Manages loop, parsing, tool execution, and prompt formatting |
| Tools (e.g., Tavily) | Provide external real-world information                      |

---

## ‚úÖ Final Insight

This architecture allows GPT to **act like an agent** ‚Äî not just answering based on knowledge, but actively searching, observing, and deciding ‚Äî all controlled via prompt loops and LangChain's agent orchestration.
